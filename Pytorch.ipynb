{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad = 6.0\n",
      "x.grad.item() = 6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Find derivative of y(x) = x^2 + 2x + 5 at x=3\n",
    "\n",
    "x = torch.tensor(2., requires_grad=True)\n",
    "y = x**2 + 2*x + 5\n",
    "y.backward()\n",
    "print (f'x.grad = {x.grad}')\n",
    "print (f'x.grad.item() = {x.grad.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dataset & Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, datadir=None, img_csv_file=None, transform=None):\n",
    "        self.datadir = datadir\n",
    "        self.transform = transform\n",
    "        self.df = pd.read_csv(os.path.join(self.datadir, img_csv_file))\n",
    "        \n",
    "    def __getitem__ (self, idx):\n",
    "        cat = self.df.iloc[idx][0]\n",
    "        img = self.df.iloc[idx][1]\n",
    "        img_arr = Image.open(os.path.join(self.datadir, img))\n",
    "        \n",
    "        if (self.transform):\n",
    "            # transform converts to a (1,20,20) tensor, which is then reshaped to a (20,20) tensor or numpy array\n",
    "            img_arr = self.transform(img_arr)\n",
    "            img_arr = torch.reshape(img_arr, (20,20))\n",
    "            #             img_arr = self.transform(img_arr).numpy().reshape(20,20)\n",
    "            \n",
    "        plt.imshow(img_arr)\n",
    "        plt.title(cat)\n",
    "        return(cat, img)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(self.df.shape[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "croptensor_data_transform = transforms.Compose([transforms.CenterCrop(20), transforms.ToTensor()])\n",
    "dataset = Dataset(datadir=\"./data\" , img_csv_file=\"index.csv\", transform=None )\n",
    "dataset = Dataset(datadir=\"./data\" , img_csv_file=\"index.csv\", transform=croptensor_data_transform)\n",
    "\n",
    "dataset[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Without Transforms\n",
    "dataset = Dataset('./data', 'index.csv')\n",
    "plt.figure(figsize=(30,20))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    dataset[i]\n",
    "\n",
    "# With Transforms\n",
    "dataset = Dataset('./data', 'index.csv', transform=croptensor_data_transform)\n",
    "plt.figure(figsize=(30,20))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    dataset[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.randint(1,5,(3,1))\n",
    "w = torch.tensor(2.0)\n",
    "b = torch.tensor(-1.0)\n",
    "\n",
    "print (x)\n",
    "\n",
    "y = w*x + b\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# y = 0.7645x + 0.8300  (w=0.7645, b=0.8300), for random seed 42\n",
    "lr = Linear(in_features=1, out_features=1, bias=True)\n",
    "print (f'Parameters = {list(lr.parameters())}')\n",
    "print ('-'*50)\n",
    "print(lr.state_dict())\n",
    "print (lr.state_dict().keys())\n",
    "for key, val in lr.state_dict().items():\n",
    "    print (f'{key} = {val}')\n",
    "print ('-'*50)\n",
    "x = torch.tensor([[1.], [2.]])\n",
    "x = torch.randn(5,1)\n",
    "yhat = lr(x)\n",
    "print ('x = ', x)\n",
    "print ('yhat = ', yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create custom nn Module\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class LR(nn.Module):\n",
    "    def __init__ (self, input_size, outout_size):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr_model = nn.Linear(input_size, outout_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = self.lr_model(x)\n",
    "        return (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = LR(1,1)\n",
    "print(\"The parameters: \", list(lr.parameters()))\n",
    "print(\"Linear model: \", lr.lr_model)\n",
    "print ('-'*50)\n",
    "x = torch.randn(5,1)\n",
    "yhat = lr(x)\n",
    "print ('x = ', x)\n",
    "print ('yhat = ', yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Loss & Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create Dataset class\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(45)\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.x = torch.linspace(-6,6,steps=size).view(-1,1)\n",
    "        self.f = 1 * self.x -1\n",
    "        self.y = self.f + torch.randint(-10,10,(size,1)) * 0.01\n",
    "        self.len = self.x.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "       return (self.x[idx], self.f[idx], self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.len)\n",
    "\n",
    "############\n",
    "size = 100\n",
    "dataset = Dataset(size)\n",
    "############\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(dataset.x, dataset.f, 'b')\n",
    "plt.plot(dataset.x, dataset.y, 'rx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create Model\n",
    "from torch import nn, optim\n",
    "\n",
    "class LR(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr_model = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward (self, x):\n",
    "        yhat = self.lr_model(x)\n",
    "        return (yhat)\n",
    "    \n",
    "# Instantiate model\n",
    "model = LR(1,1)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cost function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Create optimzier\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "list(model.parameters()), optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "\n",
    "trainloader = DataLoader(dataset=dataset, batch_size=1)\n",
    "\n",
    "def train_model_BGD(iter):\n",
    "    for epoch in range(iter):\n",
    "        for x, f, y in trainloader:\n",
    "            yhat = model(x)\n",
    "            loss = criterion(yhat, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "train_model_BGD(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w = model.state_dict()['lr_model.weight'].item()\n",
    "b = model.state_dict()['lr_model.bias'].item()\n",
    "x = dataset.x\n",
    "y = w*x + b\n",
    "\n",
    "plt.plot(dataset.x, dataset.y, 'r')\n",
    "plt.plot(x, y, 'b--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Linear, self).__init__()\n",
    "        self.lr_model = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return (self.lr_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr_model = Linear(2,1)\n",
    "lr_model.state_dict()['lr_model.weight'].shape\n",
    "\n",
    "x = torch.randn((5,2))\n",
    "lr_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.randint(0,5,(1,2))\n",
    "b = torch.randint(0,5,(2,2))\n",
    "c = torch.randint(0,5,(1,2))\n",
    "\n",
    "print (a)\n",
    "print (20*'-')\n",
    "print (b)\n",
    "print (20*'-')\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(45)\n",
    "x = torch.randn(3,2)\n",
    "# x = torch.ones(3,1)\n",
    "logR_seq_model = nn.Sequential(nn.Linear(2,1), nn.Sigmoid())\n",
    "print ('x = ', x)\n",
    "print ('\\nModel parameters = \\n', logR_seq_model.parameters, '\\nModel state dictionary = \\n', logR_seq_model.state_dict())\n",
    "print ('-'*30)\n",
    "print ('Model predictions = \\n', logR_seq_model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "\n",
    "class logR(Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(logR, self).__init__()\n",
    "        self.logR_model = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        yhat = self.logR_model(torch.sigmoid(x))\n",
    "        return (yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(45)\n",
    "\n",
    "logR_custom_model = logR(2,1)\n",
    "logR_custom_model.state_dict()['logR_model.weight'].data[0] = torch.tensor([[-0.1108, -0.3715]])\n",
    "logR_custom_model.state_dict()['logR_model.bias'].data[0] = torch.tensor([0.4399])\n",
    "print (logR_custom_model.state_dict())\n",
    "\n",
    "print ('x = ', x)\n",
    "print ('\\nModel parameters = \\n', logR_custom_model.parameters, '\\nModel state dictionary = \\n', logR_custom_model.state_dict())\n",
    "print ('-'*30)\n",
    "print ('Model predictions = \\n', logR_custom_model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Binary Classification - using Sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cerate dataset\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, samples=5, input_size=2, output_size=1, classes=2):\n",
    "        self.x = torch.randn(samples, input_size, dtype=torch.float32)\n",
    "        self.y = torch.zeros(samples,1)\n",
    "        self.y[torch.sum(self.x, dim=1)>0] = 1\n",
    "        self.len = self.x.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (self.len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cerate custom model\n",
    "\n",
    "class logR(nn.Module):\n",
    "    def __init__(self, input_size=2, output_size=1):\n",
    "        super(logR, self).__init__()\n",
    "        self.logR_model = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return (torch.sigmoid(self.logR_model(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(45)\n",
    "\n",
    "# Initiialize datset & model\n",
    "dataset = Data(samples=1000, input_size=3, output_size=1, classes=2)\n",
    "trainloader = DataLoader(dataset=dataset, batch_size=1)\n",
    "logR_model = logR(input_size=3, output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "def train_model_logR(iter=5):\n",
    "    for epoch in range(iter):\n",
    "        for x, y in trainloader:\n",
    "            yhat = logR_model(x)\n",
    "            loss = criterion(yhat, y.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            return (loss)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(logR_model.parameters(), lr=learning_rate)\n",
    "train_model_logR(iter=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Predict & check accuracy\n",
    "\n",
    "yhat = logR_model(dataset.x)\n",
    "yhat[yhat >= 0.5] = 1\n",
    "yhat[yhat < 0.5] = 0\n",
    "print (f'Accuracy = {(yhat == dataset.y).sum().item()/len(yhat)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yhat = logR_model(dataset.x)\n",
    "label = yhat > 0.5\n",
    "print(\"The accuracy: \", torch.mean((label == dataset.y.type(torch.ByteTensor)).type(torch.float)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Multiclass Classification - using Softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get training & validation data\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the training dataset:\\n \", train_dataset)\n",
    "\n",
    "# Create and print the validating dataset\n",
    "\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the validating dataset:\\n \", validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range (1,6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.imshow(train_dataset[i-1][0].view(28,28))\n",
    "    plt.title(train_dataset[i-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Softmax(nn.Module):\n",
    "    def __init__(self, input_size=None, output_size=None):\n",
    "        super(Softmax, self).__init__()\n",
    "        self.softmax_model = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return (self.softmax_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "softmax_model = Softmax(input_size=784, output_size=10)\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(softmax_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32)\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train & Validate\n",
    "\n",
    "def train_val_model_softmax(epochs=5):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Train model\n",
    "        total = 0\n",
    "        for x_train, y_train in train_loader:\n",
    "            z_train_pred = softmax_model(x_train.view(-1,784))\n",
    "            loss = criterion(z_train_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "#             training_loss.append(loss.data.item())\n",
    "    \n",
    "        # Predict & validate model\n",
    "        correct = 0\n",
    "        for x_test, y_test in validation_loader:\n",
    "            z = softmax_model(x_test.view(-1, 28 * 28))\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "        accuracy = correct / test_samples\n",
    "        validation_loss.append(loss.data)\n",
    "        validation_accuracy.append(accuracy)\n",
    "        \n",
    "epochs=10\n",
    "test_samples = len(validation_dataset)   \n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "\n",
    "train_val_model_softmax(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "ax1 = plt.subplot(1,1,1)\n",
    "ax1.plot(validation_accuracy, linewidth=3)\n",
    "ax1.set_xlabel('epochs', fontsize=18)\n",
    "ax1.set_ylabel('accuracy', fontsize=18)\n",
    "ax1.legend(['val accuracy'], loc=3)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(validation_loss, 'r--')\n",
    "ax2.set_ylabel('loss', fontsize=18)\n",
    "ax2.legend(['val loss'], loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = 99\n",
    "\n",
    "img = validation_loader.dataset[idx][0].view(-1,28)\n",
    "label = validation_loader.dataset[idx][1]\n",
    "pred = softmax_model(validation_loader.dataset[idx][0].view(-1,28*28))\n",
    "plt.imshow(img)\n",
    "plt.title(f'label={label}   Prediction={pred.argmax().item()}', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get training & validation data\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the training dataset:\\n \", train_dataset)\n",
    "\n",
    "# Create and print the validating dataset\n",
    "\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "print(\"Print the validating dataset:\\n \", validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialize Neural Net with 784 input neurons, 100 hidden neurons & 10 output neurons using Sequential model\n",
    "nn1 = nn.Sequential(\n",
    "    nn.Linear(784, 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 10),\n",
    "#     nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size=None, hlayer1_size=None, output_size=None):\n",
    "        super(NN, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hlayer1_size)\n",
    "        self.linear2 = nn.Linear(hlayer1_size, output_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialize Neural Net with 784 input neurons, 100 hidden neurons & 10 output neurons\n",
    "nn1 = NN(input_size=28*28, hlayer1_size=100, output_size=10)\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(nn1.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32)\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train & Validate\n",
    "\n",
    "def train_val_model_nn1(epochs=5):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Train model\n",
    "        total = 0\n",
    "        for x_train, y_train in train_loader:\n",
    "            z_train_pred = nn1(x_train.view(-1,784))\n",
    "            loss = criterion(z_train_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            training_loss.append(loss.data.item())\n",
    "    \n",
    "        # Predict & validate model\n",
    "        correct = 0\n",
    "        for x_test, y_test in validation_loader:\n",
    "            z = nn1(x_test.view(-1, 28 * 28))\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "        accuracy = correct / test_samples\n",
    "        validation_loss.append(loss.data)\n",
    "        validation_accuracy.append(accuracy)\n",
    "        \n",
    "epochs=10\n",
    "test_samples = len(validation_dataset)   \n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "\n",
    "train_val_model_nn1(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "ax1 = plt.subplot(1,1,1)\n",
    "ax1.plot(validation_accuracy, linewidth=3)\n",
    "ax1.set_xlabel('epochs', fontsize=18)\n",
    "ax1.set_ylabel('accuracy', fontsize=18)\n",
    "ax1.legend(['val accuracy'], loc=3)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(validation_loss, 'r--')\n",
    "ax2.set_ylabel('loss', fontsize=18)\n",
    "ax2.legend(['val loss'], loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feed Forward Network - Without Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \n",
    "    #  modified from: http://cs231n.github.io/neural-networks-case-study/\n",
    "    # Constructor\n",
    "    def __init__(self, K=3, N=500):\n",
    "        D = 2\n",
    "        X = np.zeros((N * K, D)) # data matrix (each row = single example)\n",
    "        y = np.zeros(N * K, dtype='uint8') # class labels\n",
    "        for j in range(K):\n",
    "          ix = range(N * j, N * (j + 1))\n",
    "          r = np.linspace(0.0, 1, N) # radius\n",
    "          t = np.linspace(j * 4, (j + 1) * 4, N) + np.random.randn(N) * 0.2 # theta\n",
    "          X[ix] = np.c_[r * np.sin(t), r*np.cos(t)]\n",
    "          y[ix] = j\n",
    "        self.y = torch.from_numpy(y).type(torch.LongTensor)\n",
    "        self.x = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "        self.len = y.shape[0]\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, index):    \n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, Layers):\n",
    "        super(NN, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            self.hidden.append(nn.Linear(input_size, output_size))\n",
    "            \n",
    "    # Predict\n",
    "    def forward(self, x):\n",
    "        nn_len = len(self.hidden)\n",
    "        for i, layer in enumerate(self.hidden):\n",
    "            if (i < nn_len-1):\n",
    "                x = F.relu(layer(x))\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(45)\n",
    "\n",
    "dataset = Data()\n",
    "Layers = [2, 50, 3]\n",
    "\n",
    "in_size = Layers[0]\n",
    "n_hidden = Layers[1]\n",
    "out_size = Layers[2]\n",
    "\n",
    "nn_m = NN(Layers)\n",
    "model = nn_m\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The function to calculate the accuracy\n",
    "def accuracy(model, dataset):\n",
    "    _, yhat = torch.max(model(dataset.x), 1)\n",
    "    return (yhat == dataset.y).numpy().mean()\n",
    "\n",
    "# Train & Validate\n",
    "def train_val_model(dataset=None, train_loader=None, model=None, optimizier=None, criterion=None, epochs=5):\n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Train model\n",
    "        for x_train, y_train in train_loader:\n",
    "            z_train_pred = model(x_train)\n",
    "            loss = criterion(z_train_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            training_loss.append(loss.item())\n",
    "        training_accuracy.append(accuracy(model, dataset))\n",
    "    return (training_accuracy, training_loss)\n",
    "\n",
    "training_accuracy, training_loss = train_val_model(dataset=dataset, train_loader=train_loader, model=model, optimizier=optimizer, \n",
    "                                criterion=criterion, epochs=100)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(training_accuracy, linewidth=3)\n",
    "plt.title ('Training Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(training_loss[::500], 'r--', linewidth=2)\n",
    "plt.title ('Training Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feed Forward Network - With Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.backends import cudnn\n",
    "torch.manual_seed(45)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed(45)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(45)\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create data class for creating dataset object\n",
    "\n",
    "class Data(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, N_SAMPLES=1000, noise_std=0.15, train=True):\n",
    "        a = np.matrix([-1, 1, 2, 1, 1, -3, 1]).T\n",
    "        self.x = np.matrix(np.random.rand(N_SAMPLES, 2))\n",
    "        self.f = np.array(a[0] + (self.x) * a[1:3] + np.multiply(self.x[:, 0], self.x[:, 1]) * a[4] + np.multiply(self.x, self.x) * a[5:7]).flatten()\n",
    "        self.a = a\n",
    "       \n",
    "        self.y = np.zeros(N_SAMPLES)\n",
    "        self.y[self.f > 0] = 1\n",
    "        self.y = torch.from_numpy(self.y).type(torch.LongTensor)\n",
    "        self.x = torch.from_numpy(self.x).type(torch.FloatTensor)\n",
    "        self.x = self.x + noise_std * torch.randn(self.x.size())\n",
    "        self.f = torch.from_numpy(self.f)\n",
    "        self.a = a\n",
    "        if train == True:\n",
    "            torch.manual_seed(1)\n",
    "            self.x = self.x + noise_std * torch.randn(self.x.size())\n",
    "            torch.manual_seed(0)\n",
    "        \n",
    "    # Getter        \n",
    "    def __getitem__(self, index):    \n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Make a multidimension ploynomial function\n",
    "    def multi_dim_poly(self, x):\n",
    "        x = np.matrix(x)\n",
    "        out = np.array(self.a[0] + (x) * self.a[1:3] + np.multiply(x[:, 0], x[:, 1]) * self.a[4] + np.multiply(x, x) * self.a[5:7])\n",
    "        out = np.array(out)\n",
    "        return out\n",
    "    \n",
    "# Cerate dataset\n",
    "dataset = Data()\n",
    "\n",
    "# Split into train & validation datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset.x.numpy(), dataset.y.numpy(), test_size=0.2,\n",
    "                                                   random_state=42)\n",
    "\n",
    "# Switch back from numpy to Pytorch tensor & dataset\n",
    "x_train_tensor = torch.tensor(x_train)\n",
    "x_test_tensor= torch.tensor(x_test)\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "y_test_tensor = torch.tensor(y_test)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "x = train_dataset[:][0]\n",
    "y = train_dataset[:][1]\n",
    "\n",
    "x_min, x_max = x[:, 0].min(), x[:, 0].max()\n",
    "y_min, y_max = x[:, 1].min(), x[:, 1].max() \n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "Z = dataset.multi_dim_poly(np.c_[xx.ravel(), yy.ravel()]).flatten()\n",
    "f = np.zeros(Z.shape)\n",
    "f[Z > 0] = 1\n",
    "f = f.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x[y == 0, 0].numpy(), x[y == 0,1].numpy(), 'bo', label='y=0')\n",
    "plt.plot(x[y == 1, 0].numpy(), x[y == 1,1].numpy(), 'ro', label='y=1')\n",
    "plt.contour(xx, yy, f,cmap=plt.cm.Paired)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 2\n",
    "hidden_size = 300 \n",
    "num_classes = 2\n",
    "dropout = 0.5\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Create model class - default weight intialization\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, p=0):\n",
    "        super(NN, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.drop = nn.Dropout(p=p)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.drop(out)\n",
    "        out = self.act(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.act(out)\n",
    "        out = self.l3(out)\n",
    "        return (out)\n",
    "\n",
    "# Create model class - Xavier intialization   \n",
    "class NN_X(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, p=0):\n",
    "        super(NN_X, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.xavier = torch.nn.init.xavier_uniform_(self.l1.weight)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.drop = nn.Dropout(p=p)\n",
    "        self.act = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.drop(out)\n",
    "        out = self.act(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.act(out)\n",
    "        out = self.l3(out)\n",
    "        return (out)\n",
    "    \n",
    "# Create model class - Xavier intialization   \n",
    "class NN_HE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, p=0):\n",
    "        super(NN_HE, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.he = torch.nn.init.kaiming_uniform_(self.l1.weight, nonlinearity='relu')\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.drop = nn.Dropout(p=p)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.drop(out)\n",
    "        out = self.act(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.act(out)\n",
    "        out = self.l3(out)\n",
    "        return (out)    \n",
    "    \n",
    "# Instantiate model\n",
    "# model = NN(input_size, hidden_size, num_classes, p=dropout).to(device)\n",
    "model = NN_X(input_size, hidden_size, num_classes, p=dropout).to(device)\n",
    "# model = NN_HE(input_size, hidden_size, num_classes, p=dropout).to(device)\n",
    "\n",
    "# Define Loss & Optimzier\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to train the model & compute training loss/accuracy\n",
    "def train_model():\n",
    "    n_correct = 0\n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    total_samples = 0\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for i, (x_train, y_train) in enumerate(train_loader):\n",
    "            x_train = x_train.to(device)\n",
    "            y_train = y_train.to(device)\n",
    "            # Forward pass\n",
    "            yhat_train = model(x_train)\n",
    "            loss = criterion(yhat_train, y_train)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(yhat_train.data, 1)\n",
    "            n_correct += (predicted == y_train).sum().item()\n",
    "            total_samples+=len(y_train)\n",
    "            \n",
    "        # Append loss & accuracy after each epoch\n",
    "        train_loss.append(loss.item())\n",
    "        train_accuracy.append(n_correct/total_samples)\n",
    "    return(train_accuracy, train_loss)\n",
    "\n",
    "# Train the model\n",
    "train_accuracy, train_loss = train_model()\n",
    "\n",
    "# Plot training accuracy & loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_accuracy[::25])\n",
    "plt.title ('Training Accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_loss[::25])\n",
    "plt.title ('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to test the model & compute testing loss/accuracy\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "def test_model():\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        test_accuracy = []\n",
    "        test_loss = []\n",
    "        total_samples = 0\n",
    "        for i, (x_test, y_test) in enumerate(test_loader):\n",
    "            x_test = x_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            yhat_test = model(x_test)\n",
    "            loss = criterion(yhat_test, y_test)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(yhat_test.data, 1)\n",
    "            n_correct += (predicted == y_test).sum().item()\n",
    "            total_samples+=len(y_test)\n",
    "            \n",
    "            # Append loss & accuracy after each epoch\n",
    "            test_loss.append(loss.item())\n",
    "            test_accuracy.append(n_correct/total_samples)\n",
    "\n",
    "        return(test_accuracy, test_loss)\n",
    "    \n",
    "# Test the model\n",
    "\n",
    "test_accuracy, test_loss = test_model()\n",
    "\n",
    "# Plot training accuracy & loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(test_accuracy)\n",
    "plt.title ('Testing Accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(test_loss)\n",
    "plt.title ('Testing Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Face Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# Modified code from adarsh1021 \n",
    "# https://github.com/adarsh1021/facedetection/blob/master/detect_face_video.py\n",
    "# ebharucha: 12/7/2020\n",
    "################################################################################################################################\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "label = input('Enter the face label: ')\n",
    "\n",
    "if not os.path.exists(f'./images/{label}'):\n",
    "    os.makedirs('./images/{label}')\n",
    "\n",
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# To capture video from webcam. \n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "count = 1\n",
    "\n",
    "while tqdm(True):\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "\n",
    "    # Convert to grayscale\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect the faces\n",
    "    # faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.1, 4)\n",
    "\n",
    "    # Draw the rectangle around each face & store images\n",
    "    for (x, y, w, h) in faces:\n",
    "        # cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        cv2.rectangle(img, (x-30, y-70), (x + w + 20, y + h + 20), (255, 0, 0), 2)\n",
    "        print(x, y, w, h)\n",
    "        # Write image\n",
    "        # cv2.imwrite(f'./images/{label}/{label}_{count}.jpg', gray[y-70:y+h+20,x-30:x+w+20])\n",
    "        cv2.imwrite(f'./images/{label}/{label}_{count}.jpg', img[y-70:y+h+20,x-30:x+w+20])\n",
    "        count += 1\n",
    "        # Display\n",
    "        cv2.imshow('img', img)\n",
    "\n",
    "    # Stop if escape key is pressed or stored images exceed count \n",
    "    k = cv2.waitKey(100) & 0xff\n",
    "    if ((k==27) or (count>100)):\n",
    "        break\n",
    "        \n",
    "# Release the VideoCapture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "################################################################################################################################\n",
    "# ebharucha: 12/7/2020\n",
    "################################################################################################################################\n",
    "\n",
    "# Import dependencies\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define class to create Train & Test data\n",
    "class TrainTest():\n",
    "    def __init__(self, img_dir):\n",
    "        self.classes = []\n",
    "        imgpath = []\n",
    "        label = []\n",
    "        dirs = [x[0] for x in os.walk(img_dir)]\n",
    "        for d in dirs[1:]:\n",
    "            class_ = d.split('/')[-1]\n",
    "            self.classes.append(class_)\n",
    "            for f in os.listdir(d):\n",
    "                imgpath.append(os.path.join(f'{d}/{f}'))\n",
    "                label.append(self.classes.index(class_))\n",
    "        self.df = pd.DataFrame()\n",
    "        self.df['imgpath'] = imgpath\n",
    "        self.df['label'] = label\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.create_train_test_data(self.df)\n",
    "    \n",
    "    def create_train_test_data(self, df):\n",
    "        X = df.imgpath\n",
    "        y = df.label\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "        return(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Define dataset class\n",
    "class DatasetImg(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_arr = Image.open(self.X.iloc[idx])\n",
    "        y = self.y.iloc[idx]\n",
    "        if (self.transform):\n",
    "            X_arr = self.transform(X_arr)\n",
    "        return (X_arr, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(self.X.shape[0])\n",
    "\n",
    "# Define class to display sample images from dataloader\n",
    "class imdisplay():\n",
    "    def __init__(self, dataloader):\n",
    "        dataiter = iter(dataloader)\n",
    "        images, labels = dataiter.next()\n",
    "        self.imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "    def imshow(self, img):\n",
    "        plt.figure(figsize=(15,7))\n",
    "        img = img / 2 + 0.5  # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()\n",
    "\n",
    "# Initialize parameters\n",
    "img_dir = './data/images/'\n",
    "img_size = 128\n",
    "batch_size = 10\n",
    "img_transform = transforms.Compose([transforms.Resize(img_size), \n",
    "                                    transforms.RandomCrop(128),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.5], std=[0.5])])                                    \n",
    "\n",
    "# Create Train, Test split\n",
    "traintest = TrainTest(img_dir)\n",
    "\n",
    "# Create Train, Test datasets & dataloaders\n",
    "dataset_train = DatasetImg(traintest.X_train, traintest.y_train, img_transform)\n",
    "dataloader_train = DataLoader(dataset=dataset_train, batch_size=batch_size)\n",
    "dataset_test = DatasetImg(traintest.X_test, traintest.y_test, img_transform)\n",
    "dataloader_test = DataLoader(dataset=dataset_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import prep_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define CNN class\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3)\n",
    "        self.conv5 = nn.Conv2d(256, 512, 1)\n",
    "        self.fc1 = nn.Linear(512 * 3 * 3, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 136)\n",
    "        self.fc3 = nn.Linear(136, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))  \n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = x.view(-1, 512 * 3 * 3)\n",
    "        x = F.relu(self.fc1(x))               \n",
    "        x = F.relu(self.fc2(x))               \n",
    "        x = self.fc3(x)                       \n",
    "        return x\n",
    "\n",
    "# Function to plot Accuracy & Loss\n",
    "def plot_acc_loss(train_test, accuracy, loss_):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(accuracy)\n",
    "    plt.title (f'{train_test} Accuracy')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(loss_)\n",
    "    plt.title (f'{train_test} Loss')\n",
    "    plt.show()\n",
    "\n",
    "# Function to train model\n",
    "def train_model(model, num_epochs, dataloader, device, criterion, optimizer):\n",
    "    n_correct = 0\n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    total_samples = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (X_train, y_train) in tqdm(enumerate(dataloader)):\n",
    "            X_train = X_train.to(device)\n",
    "            y_train = y_train.to(device)\n",
    "            # Forward pass\n",
    "            yhat_train = model(X_train)\n",
    "            loss = criterion(yhat_train, y_train)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(yhat_train.data, 1)\n",
    "            n_correct += (predicted == y_train).sum().item()\n",
    "            total_samples+=len(y_train)\n",
    "        \n",
    "        # Loss & accuracy per epoch\n",
    "        train_loss.append(loss.item())\n",
    "        train_accuracy.append(n_correct/total_samples)        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs} => Training Loss: {loss.item():.4f}')\n",
    "    \n",
    "    plot_acc_loss(train_test='Train', accuracy=train_accuracy, loss_=train_loss)\n",
    "\n",
    "    return (model)\n",
    "\n",
    "# Function to test model\n",
    "def test_model(model, dataloader, device, criterion):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        test_accuracy = []\n",
    "        test_loss = []\n",
    "        total_samples = 0\n",
    "        for i, (X_test, y_test) in enumerate(dataloader):\n",
    "            X_test = X_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            yhat_test = model(X_test)\n",
    "            loss = criterion(yhat_test, y_test)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(yhat_test.data, 1)\n",
    "            n_correct += (predicted == y_test).sum().item()\n",
    "            total_samples+=len(y_test)\n",
    "            \n",
    "            # Append loss & accuracy\n",
    "            test_loss.append(loss.item())\n",
    "            test_accuracy.append(n_correct / total_samples)\n",
    "            \n",
    "        # Print Test Accuracy & Loss\n",
    "        print (f'Test Accuracy: {test_accuracy[-1]:.4f}')\n",
    "        print (f'Test Loss: {test_loss[-1]:.4f}')\n",
    "\n",
    "    plot_acc_loss(train_test='Test', accuracy=test_accuracy, loss_=test_loss)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 3\n",
    "batch_size = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate model\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "# Define Loss & Optimzier\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Train model        \n",
    "model = train_model(model, num_epochs, prep_data.dataloader_train, device, criterion, optimizer)\n",
    "# Test model\n",
    "test_model(model, prep_data.dataloader_test, device, criterion)\n",
    "\n",
    "MODELPATH = './models/cnn1.pt'\n",
    "torch.save(model, MODELPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CNN - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|                                                                   | 1/5 [00:03<00:12,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 => Training Loss: 0.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|                                                  | 2/5 [00:05<00:08,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 => Training Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|                                 | 3/5 [00:08<00:05,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 => Training Loss: 0.0769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|                | 4/5 [00:11<00:02,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 => Training Loss: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:13<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 => Training Loss: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAE/CAYAAAB8VnbnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd8XPWV///XUbdktbHkpjayccUYF0m2aU4gBQKBUMLSExICpG2y3+xusvlt++1+d7/Z/e13H1/2sfnGEFLAlEBsIJA4kAQI1UXFvYGxVS1bsiXLsiSrzef3x4yJEDYe2yPd0cz7+Xjo8dDMvXfuGZc7Z+499xxzziEiIiIiIyvB6wBERERE4oGSLhEREZFRoKRLREREZBQo6RIREREZBUq6REREREaBki4RERGRUaCkS8JmZolmdszMir2ORURkNOi4J5GkpCuGhQ4UJ34CZtYz5PHtZ/p6zrlB59x451z9OcSUaWbdZvb82b6GiMipRNNxz8zOMzM1w5T3JXkdgIwc59z4E7+bWS1wj3PuD6da38ySnHMDIxzWzUAPcJWZTXTOtYzw/t43Su9PRDwUpcc9EUBnuuKamf1PM3vKzJ40s07gDjNbZmbrzOyImTWb2X+ZWXJo/SQzc2bmDz1+LLT8t2bWaWZrzaz0NLv9AvDfwE7gtmHxlJjZc2bWamaHzOyBIcvuM7Ndof1sM7MLh8czJKZ/DP3+CTOrNbPvm9kB4MdmNsHM1oT20W5mL5hZwZDtJ5jZz0Pvvd3MVoee32VmVw1ZLzW0fN4Z/8GLiGc8Ou6dLI600Os0m1mTmf2nmaWElk0MHaeOmFmbmb0+ZLvvm9l+MzsaOi59LBJ/LjI6lHTJ9cATQDbwFDAAfAvIAy4GrgTu+4jtbwP+DvAB9cA/n2pFM5sGXBLa3+PAXUOWJQG/AfYAfqAIeDq07Fbgb4HbgSzgBqAtzPdXCIwHioGvEfw3/+PQ4xKgH3hgyPpPACnAXGDSkGWPAncMWe8aoNY5ty3MOEQkeozace8j/D1QBswHFob2+zehZX8F7AXygcmhfWFm54fiWuScywKuCu1fxgglXfKmc+4F51zAOdfjnKt0zq13zg045/YCDwHLP2L7Vc65KudcP8FEasFHrHsXUOOc2w08CSwwswtCy5YRPOB91znXFYrlrdCye4AfOOeqXdA7zrmGMN/fAPCPzrm+0Gu2OueeDf1+FPjXE+/PzIqAK4CvOufaQ9uc+Ia5EvismZ24dHFn6DkRGXtG87h3KrcTPDa1hsos/ongcQWCXwanAsWh49BroecHgDTg/NBl0X2heGWMUNIlH0hezGy2mf3GzA6Y2VGCB4K8j9j+wJDfuwmeVfoQMzOCSdfjAKGi1DcJXm6E4JmtWufc4Ek2LwLeC+O9nMxB51zfkDgyzOxhM6sPvb9X+NP7KwIOOec6hr9IKMnbAFxvZj7gUwS/KYvI2DMqx73TmALUDXlcB5wodfhB6PHLZvaemf0VQOgL63dC8bWELpFOPot9i0eUdMnwO2seBLYB54VOX/89YBHYz6VAKfB3oQPbAWAxcLuZJRI8CJaEfh+uAZj+ocCDxa+9QPqQp4cfgIa/v78OxVERen+XD9tPnpllneI9PELwEuOfAa875w6cYj0RiW6jddz7KM0ESxxOKAaaAJxzR51zf+Gc8wOfA75rZstDyx5zzl1M8DiWCPyvEY5TIkhJlwyXCXQAXWY2h4+uazgTXwBeJFgrtSD0cwHBGq1PAWuBw8C/mlm6mY0zs4tD2z4M/LWZLbSgGaFLgQCbCSVuZnY1wZqx072/bqDdzCYQPLgC75/N+gPwQzPLMbNkM7tsyLbPAEuAbxCs8RKR2DBSxz3g/aL5oT8JBEss/t7M8swsn2Dd1mOh9T9rZtNDVwg6gEFg0MzmmNnHzSyV4F3gPaFlMkYo6ZLhvkMwQeok+O3vqXN9QTNLBz4P/Jdz7sCQn70ELzd+IXTW6hpgDsEzTvXATQDOuSeBfwvFcpRg8pMbevk/J1gUeyS0j9P1//pPgsWzh4G3gd8OW36iWP4d4CDwzRMLnHNdwHMEv5E+dwZ/BCIS3SJ+3BumZ9jPZcD/S/BL41ZgC7CeP521mkWw9OEY8BbwgHPuTSAV+HfgEMFLnLkEbzKSMcKcU982kXCZ2T8RLG79otexiIjI2KLmqCJhCl2OvJtgTZeIiMgZ0eVFkTCY2VcJXvL8lXPuba/jERGRsUeXF0VERERGgc50iYiIiIwCJV0iIiIioyAqC+nz8vKc3+/3OgwRGSXV1dWHnHP5XscRCTp+icSfcI9hUZl0+f1+qqqqvA5DREaJmdWdfq2xQccvkfgT7jFMlxdFRERERoGSLhEREZFRoKRLREREZBQo6RIREREZBUq6REREREaBki4RiWlmdqWZ7TazPWb2vZMsn21ma82s18z+csjzRWb2qpntNLPtZvat0Y1cRGJNVLaMEBGJBDNLBH4IfBJoBCrN7Hnn3I4hq7UBfw58btjmA8B3nHM1ZpYJVJvZ74dtKyISNp3pEpFYVgHscc7tdc71Ab8Arhu6gnOuxTlXCfQPe77ZOVcT+r0T2AkUjE7YIhKLlHSJSCwrABqGPG7kLBInM/MDC4H1EYlKROKSki4RiajWzl5+WdXAnpZjXocCYCd5zp3RC5iNB1YD33bOHT3FOveaWZWZVbW2tob1us0dPfz8rX0c6x04k3BEZAxTTZeInJNAwLG1qYNXdrXw6u4WtjR2APBXn57FeRPP8zg6GoGiIY8Lgf3hbmxmyQQTrsedc8+caj3n3EPAQwBlZWVhJXXvHjzGP76wg2n547lsZkyMnRSR01DSJSJnrPN4P2+8e4hXdrXwx92tHDrWixksLMrhLz81k4/PnsjcKVlehwlQCcwws1KgCbgFuC2cDc3MgJ8AO51z/xnpwBaV5JJgUFnbpqRLJE4o6RKR03LO8V5rF6/uauGVXS1U1rYxEHBkpSWxfNZELp+dz/KZE/FlpHgd6gc45wbM7BvAS0Ai8FPn3HYzuz+0fIWZTQaqgCwgYGbfBuYC84E7ga1mtin0kt93zq2JRGzjU5M4f2o2G/a1ReLlRGQMUNIlIid1vH+Q9fva3k+06tu6AZg1KZN7Lp3G5bMnsqg4h6TE6C4NDSVJa4Y9t2LI7wcIXnYc7k1OXhMWMeV+H4+vr6NvIEBKUnT/OYrIuVPSJSLva+7o4dVdrbyyq4W39hyip3+QtOQELp6ex72XTePjsydSkDPO6zBjRkVpLj99ax9bmzpYXJLrdTgiMsKUdInEscGAY2N9O6+EzmbtOtAJQGHuOD5fVsjHZ09k2bQJpCUnehxpbFpc4gOCdV1KukRin5IukThzpLuP194Jns167Z1WjnT3k5hglJXk8jdXzeby2RM5b+J4gnXkMpLyM1OZlpdB5b427l8+3etwRGSEKekSiXHOOXYd6Ay2dNjVQk19OwEHEzJSuHz2RC6fPZFLZ+STPS7Z61DjUrnfx4vbDxAIOBISlOiKxDIlXSIxqLtvgLf2HA61dGihueM4ABcUZPONy2dw+eyJzC/I1od8FCgv9fFUVQPvtHQye3JUtNkQkRGipEskRtQf7uaVXQd5ZXcr6/Yepm8gQEZKIpfOyOcvPjGRj83KZ2JWmtdhyjAV/lBd1742JV0iMU5Jl8gY1T8YoLL2Ty0d3mvtAmBaXgZ3Li3h8tkTKff71IogyhX5xjEpK5UNte3cuczvdTgiMoKUdImMIa2dvfxxd3DczhvvHKKzd4CUxASWTPNx+5JgouXPy/A6TDkDZka530flvjacc7qBQSSGKekSiWKnmms4KSuVay6cwsdnTeTi8/LISNV/5bGsotTHr7c009jeQ5Ev3etwRGSE6EgtEmXCnWuoMyKxozxU17VhX5uSLpEYpqRLxGNjda6hRM6sSZlkpSVRWdvGjYtPNpFIRGJBWEmXmV0JPEBwYOzDzrkfDFueC/wUmA4cB77knNsWWpYDPAzMA1xo2dqIvQORMShW5hpKZCQkGGV+H5W1Gn4tEstOm3SZWSLwQ+CTQCNQaWbPO+d2DFnt+8Am59z1ZjY7tP4VoWUPAC86524ysxRA584lLh3vH+S325r5zZYDmmsoH1Lu9/HKrhYOH+tlwvhUr8MRkREQzpmuCmCPc24vgJn9ArgOGJp0zQX+F4BzbpeZ+c1sEtADXAZ8MbSsD+iLWPQiY8D+Iz08vr6OX2xo4HBXHwU5mmsoH1buD85erKxt58p5kz2ORkRGQjhJVwHQMORxI7Bk2DqbgRuAN82sAigBCoFBoBX4mZldCFQD33LOdZ1r4CLRzDnH2r2HefTtOn634wAAn5gziS9c5Oei6RNUBC8fckFhNilJCVTWtinpEolR4SRdJ/t0cMMe/wB4wMw2AVuBjcAAkAwsAr7pnFtvZg8A3wP+7kM7MbsXuBeguLg47DcgEk2O9Q7wbE0jj66t492WY+SmJ3Pf8uncvqSYwlxdWZdTS01KZEFRjuq6RGJYOElXI1A05HEhsH/oCs65o8DdABb8Cr8v9JMONDrn1odWXUUw6foQ59xDwEMAZWVlw5M6kaj2XusxVq6tY1V1I8d6B7igIJv/+PyFXDN/ii4fStgq/D5+9Np7dPUOqPeaSAwK5391JTDDzEqBJuAW4LahK4TuUOwO1WzdA7weSsSOmlmDmc1yzu0mWFy/A5EYMBhwvLKrhUfX1vLGu4dITjSumT+Vu5aVsKAoR5cQ5YyVl/r471f3UFPfzqUz8r0OR0Qi7LRJl3NuwMy+AbxEsGXET51z283s/tDyFcAc4FEzGySYVH15yEt8E3g8dOfiXkJnxETGqvauPp6qamDl2jqajvQwOSuNv/zUTP6svJj8TN11JmdvUXEOCRYcfq2kSyT2hHX+2jm3Blgz7LkVQ35fC8w4xbabgLJziFEkKmxr6uCRt2t5fvN+egcCLJ3m42+vnsMn505SPy2JiMy0ZOZOzWKD6rpEYpKKBkQ+Qt9AgN9ua+aRt2upqT/CuOREblpcyF3L/MyanOl1eBKDyv0+nlhfT99AgJQkJfMisURJl8hJHOg4zhPr63hiQwOHjvVSmpfB318zlxsXF5I9Ltnr8CSGVfh9/OytWrY2dbC4JNfrcEQkgpR0iYQ459iwr41H19bx4vYDBJzj8lkTuesiP5eel0dCggrjZeSVhYZfV9W2KekSiTFKuiTudfcN8NzG/Ty6tpZdBzrJHpfMly8p5Y4lJRRPUG8tGV35malMy8ugsraN+5ZP9zocEYkgJV0St2oPdbFyXR1PVzXQeXyAuVOy+LcbL+DaCwsYl6LeWuKdcr8veLY14HSGVSSGKOmSuBIIOP74TguPvF3Ha++0kpRgXHXBFL6wrITFJbnqrSVRocyfy1NVDbzbckw3bIjEECVdEheOdPfxy6pGVq6ro76tm4mZqfzFJ2Zya0URE7PSvA5P5AMqSoN1XRtq25R0icQQJV0S03bsP8qja2t5blMTx/sDVPh9/PWVs/j0+ZNJVm8tiVLFvnQmZqZSua+NO5eWeB2OiESIki6JOf2DAV7cdoBH19ZSWdtOWnIC1y8s4M6lfuZOzfI6PJHTMjPKS31U1rbhnNNlb5EYoaRLYkbL0eM8saGeJ9bX09LZS7Evnb+9eg6fX1xEdrp6a8nYUuH38ZstzTS291Dk0120IrFASZeMac45quvaeWRtHb/d2sxAwPGxWfn82zI/y2fm684vGbPKQ/26KmvblHSJxAglXTIm9fQN8vzmJh55u44dzUfJTEviCxf5uWNpCaV5GV6HJ3LOZk3OJDMticraNm5YVOh1OCISAUq6ZEypP9zNY+vreKqygY6efmZPzuRfr7+Azy2cSnqK/jlL7EhMMMpKctmwT8OvRWKFPqUk6gUCjjf2HOLRt2t5ZXcLCWZcef5k7lpWQkWpT0XGErPKS328uruVw8d6mTA+1etwROQcKemSqNXR08/q6mBvrX2Husgbn8I3P34ety4pZkr2OK/DExlxFSfmMNa18+nzJ3scjYicKyVdEnV2HTjKo2vreG5jE919gywqzuHbtyzgynmTSU3SeB6JHxcUZpOSlEDlvjYlXSIxQEmXRIVAwPHi9gM88nYt6/e1kZKUwHUXTuWuZX4uKMz2OjwRT6QmJbKgKIfKWtV1icQCJV3iueP9g/yPpzexZusBCnLG8b2rZnNzWRG+jBSvQxPxXLk/lxWv7aWrd4CMVB2yRcYy/Q8WT3V09/OVlVVs2NfG31w1m3sunUaiemuJvK/c7+OHr77HxvojXDIjz+twROQcaPiceKa5o4fPP/g2G+vbeeCWBdy3fLoSLpFhFpfkkmDB4dciMrYp6RJP7D7QyQ3/9232HznOI3dXcN2CAq9DkhhlZlea2W4z22Nm3zvJ8tlmttbMes3sL89k29GQmZbMnClZVKpfl8iYp6RLRt36vYf5/Iq3GQw4nr5vGRedp0smMjLMLBH4IXAVMBe41czmDlutDfhz4D/OYttRUe73sbGhnb6BgBe7F5EIUdIlo2rN1mbu/MkG8jJTeeZrFzF3apbXIUlsqwD2OOf2Ouf6gF8A1w1dwTnX4pyrBPrPdNvRUlHq43h/gG37O7zYvYhEiJIuGTU/f2sfX3+ihgsKs1l9/0UU5mqIr4y4AqBhyOPG0HMjvW1EvT/8WpcYRcY0JV0y4gIBxw9+u4t/fGEHn5gzicfvWUKu2kHI6DjZnRku0tua2b1mVmVmVa2trWEHF678zFRK8zLUr0tkjFPSJSOqbyDAd365mRWvvcftS4pZccdi0pLVVV5GTSNQNORxIbA/0ts65x5yzpU558ry8/PPKtDTKffnUlXXTiAQbs4oItFGSZeMmGO9A3z5kUqe3djEdz45k//5uXlqCSGjrRKYYWalZpYC3AI8PwrbRly538eR7n72tB7zKgQROUdqjiojoqXzOHf/rJJdBzr595vmc3NZ0ek3Eokw59yAmX0DeAlIBH7qnNtuZveHlq8ws8lAFZAFBMzs28Bc59zRk23rzTsJFtMDbNjXxsxJmV6FISLnQEmXRNze1mN84WcbONTZx8N3lfHx2RO9DknimHNuDbBm2HMrhvx+gOClw7C29UqxL52JmalU1rZxx9ISr8MRkbOgpEsiamN9O19+pAqAJ+9dyoKiHI8jEokNZka536c7GEXGMNV0ScS8vPMgt/54HeNTk3jmqxcp4RKJsHJ/Lvs7jtPY3u11KCJyFpR0SUT8YkM9X3m0ipmTMln91Yvw52V4HZJIzCkP1XWpdYTI2KSkS86Jc44H/vAu33tmK5fMyOfJrywlPzPV67BEYtLsyVlkpiaxYV+716GIyFlQTZectYHBAH/3q208uaGBGxcV8oMbLyA5UXm8yEhJTDAW+3N1pktkjArrE9LMrjSz3Wa2x8y+d5LluWb2rJltMbMNZjZv2PJEM9toZr+OVODirZ6+Qe5/rJonNzTw9Y9P5z8+P18Jl8goKPf72NNyjLauPq9DEZEzdNpPSTNLBH4IXAXMBW41s7nDVvs+sMk5Nx+4C3hg2PJvATvPPVyJBm1dfdz28Dpe3tXCP193Pn/16dmYqempyGioUF2XyJgVzqmJCmCPc26vc64P+AVw3bB15gIvAzjndgF+M5sEYGaFwNXAwxGLWjzT0NbNTT96m+37j/Kj2xdz5zK/1yGJxJX5hdmkJCWodYTIGBRO0lUANAx53Bh6bqjNwA0AZlYBlPCnZoP/B/hrIHBOkYrntjV1cMOP3uZwVx+P37OEK+dN9jokkbiTmpTIgsIcKutUTC8y1oSTdJ3sutHwias/AHLNbBPwTWAjMGBm1wAtzrnq0+7E7F4zqzKzqtbW1jDCktH05ruHuOWhdSQnGKvuX0a53+d1SCJxq7w0l+1NHXT3DXgdioicgXCSrkZg6OC8QmD/0BWcc0edc3c75xYQrOnKB/YBFwPXmlktwcuSl5vZYyfbiXPuIedcmXOuLD8//8zfiYyY5zY28cWfbaAwdxzPfO1iZmjum4inyv0+BgKOjfVHvA5FRM5AOElXJTDDzErNLAW4BXh+6ApmlhNaBnAP8HooEfsb51yhc84f2u4V59wdEYxfRpBzjgdfe49vP7WJMn8uT9+/jMnZaV6HJRL3FpfkkmDB4dciMnactk+Xc27AzL4BvAQkAj91zm03s/tDy1cAc4BHzWwQ2AF8eQRjllEQCDj++Tc7+NlbtVw9fwr/efOFpCYleh2WiACZacnMnpylOxhFxpiwmqM659YAa4Y9t2LI72uBGad5jT8CfzzjCGXUHe8f5DtPb+Y3W5v50sWl/O3Vc0hIUEsIkWhSUerjqcoG+gcD6pEnMkbof6p8QEdPP1/46QZ+s7WZ/+czc/j7z85VwiUShcr9Pnr6B9nW1OF1KCISJiVd8r7mjh5uXrGWmvp2HrhlAV+5bJrXIYnIKZSX5gJqkioylijpEgDeOdjJDf/3bZqO9PDzuyu4bsHwVmwiEk0mZqbhn5Cu4dciY4iSLmHDvjZu+tHbDAQcT923lIvPy/M6JBEJQ7nfR1VdG4HA8NaJIhKNlHTFud9ubeaOn6wnLzOVZ756EedPzfY6JBEJU3mpjyPd/expPeZ1KCISBiVdceyRt2v52hM1zJuaxer7L6LIl+51SCJyBipCkyHUr0tkbFDSFYecc/zbi7v4h+e3c8XsSTx+z1JyM1JOv6GIRJWSCenkZ6ZSpWJ6kTEhrD5dEjv6BwN8d/UWnqlp4rYlxfzTteeTpB4/ImOSmVHh91FZq2J6kbFAn7Zx5FjvAF/6eSXP1DTxPz45k3/53DwlXCJjXLk/l6YjPTQd6fE6FBE5DX3ixonWzl5ueWgtb793mH+/cT5/fsUMzNT0VGSsKy8N1nVVqq5LJOop6YoD+w51ccOP3uK9li4evquMm8uLvA5JRCJk9uQsMlOT2KC6LpGop5quGLep4Qhf+nklAE/eu5QFRTkeRyQikZSYYCwqydWZLpExQGe6Ytgruw5y60PrGJ+axOqvXqSESyRGVZT6eLflGO1dfV6HIiIfQUlXjHqqsp6vPFrNeRPHs/qrF1Gal+F1SCIyQspD/bo0h1EkuinpijHOOR74w7t8d/VWLj4vj1/cu5T8zFSvwxKRETS/MJuUxAQlXSJRTjVdMWRgMMDf/Wo7T26o54ZFBfzbjfNJVksIkZiXlpzIhUXZbFC/LpGopk/kGNHTN8j9j9Xw5IZ6vv7x6fzvz1+ohEskjpT7fWxv6qC7b8DrUETkFPSpHAPau/q4/eF1vLzrIP903fn81adnqweXSJwpL/UxEHBsqj/idSgicgpKusa4hrZublzxNtv2H+VHty/irmV+r0MSEQ8sLsnFDPXrEoliqukaw7bv7+CLP6ukt3+Qx+9Z8v4dTCISf7LSkpkzOUvF9CJRTGe6xqi39hzizx5cR3KCsfqrFynhEhEqSn3U1B2hfzDgdSgichJKusag5zY28cWfbaAgZxyrv3YRMyZleh2SiESBcr+Pnv5Btu8/6nUoInISSrrGEOccD73+Ht9+ahOLS3J5+v5lTMke53VYIhIlyv25gIZfi0QrJV1jRCDg+Odf7+Rf1+zi6vlTeORLFWSPS/Y6LBGJIhOz0iiZkK5iepEopUL6MeB4/yDf+eVmfrOlmbsv9vN3V88lIUEtIUTkw8r9Pl7eeZBAwOk4IRJldKYryjnn+MqjVfxmSzPf/8xs/v4aJVwiZ8LMrjSz3Wa2x8y+d5LlZmb/FVq+xcwWDVn2F2a23cy2mdmTZpY2utGfuQq/j/buft5rPeZ1KCIyjJKuKFdV184b7x7ib6+ew72XTVfTU5EzYGaJwA+Bq4C5wK1mNnfYalcBM0I/9wI/Cm1bAPw5UOacmwckAreMUuhnrbw0eCezLjGKRB8lXVFuVVUjGSmJ3Lak2OtQRMaiCmCPc26vc64P+AVw3bB1rgMedUHrgBwzmxJalgSMM7MkIB3YP1qBny3/hHTyxqeqmF4kCinpimI9fYP8ZmszV10whfQUld+JnIUCoGHI48bQc6ddxznXBPwHUA80Ax3Oud+NYKwRYWZUlOZSqeHXIlFHSVcUe2n7AY71DnDT4kKvQxEZq052Pd6Fs46Z5RI8C1YKTAUyzOyOk+7E7F4zqzKzqtbW1nMKOBLK/T6ajvTQdKTH61BEZAglXVFsVXUjhbnjqFC3eZGz1QgUDXlcyIcvEZ5qnU8A+5xzrc65fuAZ4KKT7cQ595Bzrsw5V5afnx+x4M/WiQkVVarrEokqSrqi1P4jPbz13iFuXFSouxVFzl4lMMPMSs0shWAh/PPD1nkeuCt0F+NSgpcRmwleVlxqZukWvIPlCmDnaAZ/tuZMySIzNYkNqusSiSoqFIpSz25swjm4cZEuLYqcLefcgJl9A3iJ4N2HP3XObTez+0PLVwBrgM8Ae4Bu4O7QsvVmtgqoAQaAjcBDo/8uzlxigrGoJFfDr0WijJKuKOScY3V1IxWlPoonpHsdjsiY5pxbQzCxGvrciiG/O+Drp9j2H4B/GNEAR0hFqY//76XdtHf1kZuR4nU4IkKYlxfDaC6Ya2bPhhoLbjCzeaHni8zsVTPbGWow+K1Iv4FYVFN/hL2HulRALyJnrawkOIexqk53MYpEi9MmXWE2F/w+sMk5Nx+4C3gg9PwA8B3n3BxgKfD1k2wrw6yuaWRcciKfuWDK6VcWETmJC4tySElM0CXGUdLdN0AgMPzGWJEPCudMVzjNBecCLwM453YBfjOb5Jxrds7VhJ7vJFiEOrxHjgxxvH+QFzbv56p5kxmfqqu/InJ20pITmV+YrWL6UXD0eD8X/+AV/uuVd70ORaJcOElXOM0FNwM3AJhZBVBC8Lbr95mZH1gIrD/ZTqKtz41Xfr/jIJ3HB7hRlxZF5ByVl/rY1tRBd9+A16HEtGdrmmjv7ucnb+6j83i/1+FIFAsn6QqnueAPgFwz2wR8k+BdPu//Lzez8cBq4NvOuaMn20m09bnxyqrqRqZmp7Fs2gSvQxGRMa7C72Mg4NhUf8TrUGKWc46V6+qYkp1G5/EBfrGh4fQbSdwKJ+k6bXNB59xR59zdzrk1aaR2AAAgAElEQVQFBGu68oF9AGaWTDDhetw590xEoo5RB48e5413W7lBvblEJAIWleRipuHXI2nt3sPsaTnGdz41i2XTJvCTN/fRNxDwOiyJUuEkXadtLmhmOaFlAPcArzvnjoYaCv4E2Omc+89IBh6Lnt3YRMChS4siEhHZ45KZPTmLKs1hHDGPrasjJz2Za+ZP4f6PTefA0eP8alOT12FJlDpt0uWcGwBONBfcCTx9orngiQaDwBxgu5ntIniX44nWEBcDdwKXm9mm0M9nIv4uYoBzjlXVjZSV5FKal+F1OCISIyr8udTUtzMwqLMvkXbw6HFe2n6Qm8uKSEtO5LIZecyenMmDr+/VnYxyUmH16XLOrXHOzXTOTXfO/UvouRUnGgw659Y652Y452Y7525wzrWHnn/TOWfOufnOuQWhnzUfta94taWxgz0tx3SWS0QiqrzUR3ffINv3n7ScVs7BkxvqCTjH7UuKATAz7l8+nT0tx3hlV4vH0Uk00uzFKLGqupHUpASunq/eXCISORWh4dfq1xVZ/YMBntxQz/KZ+ZRM+NPViavnT6EgZxwPvv6eh9FJtFLSFQV6BwZ5fvN+Pn3+ZLLSkr0OR0RiyMSsNEompKtfV4T9YcdBDh7t5c6lJR94PjkxgXsuLaWytp3qOv2Zywcp6YoCL+9soaOnX2N/RGRElPt9VNW1ExwzKZHw6No6CnLG8bFZEz+07M/Ki8hJT2bFa3s9iEyimZKuKLC6upHJWWlcfF6e16GISAwq9+fS1tXHe63HvA4lJuxp6WTt3sPcvrSYxJO090lPSeKuZX5+v+Mge1o6PYhQopWSLo+1dB7nj++0cv2igpP+5xUROVflobquDfvUOiISHltXT0piAjeXFZ1ynS8sKyEtOYGHXtfZLvkTJV0e+9XG/QwGHDcu0qVFERkZpXkZ5I1PUTF9BHT1DrC6upHPXDCZvPGpp1xvwvhUbi4r4tmNTRzoOD6KEUo0U9LloRO9uRYU5XDexPFehyMiMcrMKPf7VEwfAb/atJ/O3gHuXOY/7bpfuXQagwHHz97aN/KByZigpMtD2/cfZffBThXQi8iIK/f7aDrSw/4jPV6HMmY553h0bS1zp2SxqDjntOsX+dK5ev5UHl9fT0ePBmGLki5PrapuJCUpgc/On+p1KCIS4ypK1a/rXFXXtbPrQCd3LishOOXu9O67bBrHegd4Yn39CEcnY4GSLo/0DQT41aYmPjl3Etnp6s0lIiNrzpQsxqcmKek6ByvX1ZGZmsR1C8L/ojyvIJtLZ+Tx07f20TswOILRyVigpMsjr+5uob27n5tUQC8ioyAxwVhUkkul7mA8K4eO9bJmazM3Li4kPSXpjLa977LptHb28myNBmHHOyVdHllV3Uh+ZiqXzlBvLhEZHRX+XHYf7ORId5/XoYw5T1U20D/ouGNYB/pwXHzeBOYVZPGQBmHHPSVdHjh8rJdXd7Vw/cICkhL1VyAio+NEv66qWp3tOhODAccT6+u5+LwJZ3WnuZlx32XT2Xuoi9/tODgCEcpYoU98D/xq034G1JtLREbZhUU5pCQmqK7rDL26q4WmIz0fmrN4Jq6aN5liXzorXntP45jimJIuD6yqbuSCgmxmTc70OhQRiSNpyYnML8xmg5KuM/LoujomZaXyiTmTzvo1khIT+MqlpWxqOKJ+aXFMSdco27H/KDuaj6o3l4h4oszvY2tjBz19upMuHLWHunj9nVZuqyg553KQz5cVMSEjhQc1GihuKekaZatrGklONK69UL25RGT0VZTmMhBwbGxQXVc4Hl9fR1KCcUvFqecshistOZEvXOTnlV0t7D6gQdjxSEnXKOofDPbmumL2JHIzUrwOR0Ti0OISH2aodUQYjvcP8nRVI58+fzKTstIi8pp3Li1hXHIiD77+XkReT8YWJV2j6LXdrRw61qdLiyLimexxycyalKli+jC8sHk/HT393Lns7Avoh8vNSOGWiiKe37RfI5nikJKuUbS6ppEJGSksn5XvdSgiEscqSn3U1LczMBjwOpSotnJdHTMmjmdJaIRSpHz5klIc8JM3NQg73ijpGiXtXX38YedBPrewgGT15hIRD5X7fXT3DbKj+ajXoUStzQ1H2NLYcUZzFsNVmJvOtRdO5ckN9XR0axB2PNGn/yh5Yct++gfVm0tEvHdi+LVaF5zaynV1pKckcv3CghF5/Xsvm0Z33yAr19WOyOtLdFLSNUpWVTcyd0oWc6dmeR2KiMS5SVlpFPvSVdd1Cu1dfbyweT/XLywgMy15RPYxZ0oWH5uVz8/fruV4v9p3xAslXaPgnYOdbGnsUAG9iESNcr+Pqtp2dUc/iVXVjfQOBCJaQH8y9102nUPH+lhV3Tii+5HooaRrFKyubiQpwbhugXpziUh0qCjN5XBXH++1dnkdSlQJBByPra+jwu9j9uSRvTKxdJqPC4ty+PEbexnUIOy4oKRrhA0MBnhmYxMfnz2RCeNTvQ5HRAT40/BrXWL8oNffbaXucDd3jPBZLggOwr7/smnUHe7mpe0HRnx/4j0lXSPsjT2HaO3sVQG9iESV0rwM8sanUKli+g94bF0deeNTuPL8yaOyv0+dP5nSvAwNwo4TSrpG2KrqRnLTk7l89kSvQxEReZ+ZUVbi0/DrIRraunl5Vwu3lBeTkjQ6H4+JCcZXLp3GlsYO1u49PCr7FO8o6RpBHd39/H7HQa5bUDBq/4FFRMJVXuqjsb2H5g51Rgd4ckM9Bty6pHhU93vDogLyxqey4jUNwo51ygRG0Atb9tM3ENBdiyISlSr86td1Qu/AIE9VNnDFnEkU5Iwb1X2nJSdy98V+Xn+nlR371bA2linpGkGraxqZNSmT89WbS0Si0JwpmWSkJKqYHnhx2wEOd/Vx1ygU0J/MHUtKyEjRIOxYp6RrhOxpOcbG+iPctLgw4iMkRCR8Znalme02sz1m9r2TLDcz+6/Q8i1mtmjIshwzW2Vmu8xsp5ktG93oR1ZSYgKLSnKp3NfudSiee3RtHaV5GVw8Pc+T/WenJ3PbkmJ+vaWZhrZuT2KQkaeka4SsrmkkMcG4bqF6c4l4xcwSgR8CVwFzgVvNbO6w1a4CZoR+7gV+NGTZA8CLzrnZwIXAzhEPepRV+H3sPtgZ1zMAt+/voLqunduXFJOQ4N2X5C9dUoqhQdixTEnXCBgMOJ6taWL5zHwmZqZ5HY5IPKsA9jjn9jrn+oBfANcNW+c64FEXtA7IMbMpZpYFXAb8BMA51+ecOzKawY+G8tAcxqq6+L3E+Ni6etKSE/j84iJP45iSPY7rFhTwVGUD7V19nsYiIyOspCuM0/O5ZvZs6NT8BjObF+62seitPYc4cPS4CuhFvFcANAx53Bh6Lpx1pgGtwM/MbKOZPWxmGSMZrBcWFOWQnGhx2zri6PF+ntvYxLUXTiU7fWTmLJ6J+5ZPo6d/kEfX1nkdioyA0yZdYZ6e/z6wyTk3H7iL4Cn5cLeNOatrGskel8wVc9SbS8RjJ7tWNLwD5anWSQIWAT9yzi0EuoCTfnE0s3vNrMrMqlpbW88l3lGXlpzI/MKcuG2S+kx1Iz39g9y1zO91KADMnJTJFbMn8sjaWnr6NAg71oRzpiuc0/NzgZcBnHO7AL+ZTQpz25hy9Hg/L247wLUXTiU1KdHrcETiXSMw9JpRIbA/zHUagUbn3PrQ86sIJmEf4px7yDlX5pwry8/Pj0jgo6nc72NrUwfH++PrQ945x8p1dSwoymFeQbbX4bzv/o9Np62rj19WN5x+ZRlTwkm6wjk9vxm4AcDMKoASggeucLYltN2Y/aY41JotzfQOBLhRlxZFokElMMPMSs0sBbgFeH7YOs8Dd4XuYlwKdDjnmp1zB4AGM5sVWu8KYMeoRT6KKkpz6R90bKyPuZK1j7T2vcO819rFnUu9aRNxKmUluSwqzuGh1/cyMBjwOhyJoHCSrnBOz/8AyDWzTcA3gY3AQJjbBp8c498UT1hV3ch5E8dzYWH0fGsSiVfOuQHgG8BLBO88fNo5t93M7jez+0OrrQH2AnuAHwNfG/IS3wQeN7MtwALgX0ct+FG0uNiHWfwNv165ro6c9GSunj/F61A+wMy4f/l0Gtt7WLNNg7BjSVIY65z29Lxz7ihwNwR73gD7Qj/pp9s2ltQe6qKqrp3vXjlbvblEooRzbg3BxGrocyuG/O6Ar59i201A2YgGGAWy05OZNSkzrpKuAx3H+d2Og9xzSSlpydFXCvKJOZOYnp/Bij++x2fnT9FnSowI50zXaU/PhxoIpoQe3gO8HkrEwjm1HzNW1zSSYHD9wpNeQRURiVrlfh81de1xcznryQ31BJzj9iXRdWnxhIQE477LprOj+Shv7jnkdTgSIadNusI8PT8H2G5muwjeqfitj9o28m/De4GA45maJi6dkc/kbPXmEpGxpbzUR1ffIDuaY3/2X/9ggCc31POxmfkUT0j3OpxTum7hVCZmpvKgBmHHjHAuL4Zzen4twW7OYW0bi9btPUzTkR6+e9Vsr0MRETljQ4dfzy/M8TiakfW77Qdp6ezlBx7NWQxXalIiX7qklB/8dhdbGzu4QLXCY5460kfIqupGMtOS+NTcSV6HIiJyxiZnp1HkGxcXdV0r19VSmDuO5TOjv5fibUuKyUxN0iDsGKGkKwKO9Q7w220HuGb+1KgsyBQRCUe530dVbTvBewti07sHO1m3t43bl5SQ6OGcxXBlpSVz29Ji1mxtpu5wl9fhyDlS0hUBa7Y209M/qLE/IjKmVfh9HO7qY++h2P1wf2xdHSmJCdxcNnaO11+6uJSkhAQefkODsMc6JV0RsLq6kdK8DBYVx3YdhIjEthPDr2N1JFBX7wCra5q4ev4UJoxP9TqcsE3KSuP6hQU8XdXAoWO9Xocj50BJ1zlqaOtm/b42blpcqD4qIjKmTcvLIG98SswOv35uUxPHege4M8oL6E/m3uXT6BsM8OjbtV6HIudASdc5Wl3TiKk3l4jEADOjrMQXk8X0zjlWrq3j/KlZLCwae1clpueP55NzJvHI2jq6ege8DkfOkpKucxAIOFbXNHLx9Dym5ozzOhwRkXNWXuqjoa2HAx3HvQ4loqrq2tl1oJM7l5aM2asS939sOh09/TxVqUHYY5WSrnOwobaNhrYeFdCLSMx4v19XjJ3tWrm2jsy0JK5dMNXrUM7aouJcKvw+fvLmPvrjZHJArFHSdQ5WVzcyPjWJT58/2etQREQiYs6UTDJSEmOqmL61s5ffbmvmpsWFpKeE1RM8at23fBpNR3r49ZaYHWMc05R0naXuvgHWbG3m6gumMC5FvblEJDYkJSawqCQ3puq6nq5qoH/QccfSsVdAP9zHZ01k5qTxPPja3pjupxarlHSdpRe3HaCrb5AbdWlRRGJMud/H7oOddHT3ex3KORsMOB5fV8cl5+UxPX+81+Gcs4QE497LprPrQCd/fKfV63DkDCnpOkurqhsp9qVT7s/1OhQRkYgq9/twDqrqxv7Zrpd3HmR/x/GYOMt1wrUXTmVKdhoPvqbRQGONkq6z0Njezdq9h7lxkXpziUjsWVicQ3KiUVnb7nUo52zlujomZ6XxiTnRP2cxXClJCXz5klLW7W1jU8MRr8ORM6Ck6yw8W9OEc3DDIvXmEpHYk5acyAUF2WO+rmvfoS7eePcQty0pJikxtj7ubqkoJistSWe7xpjY+lc4CpwL9uZaNm0CRb50r8MRERkR5aU+tjQe4Xj/oNehnLXH19WRlGDcUl7kdSgRNz41iTuXlfDi9gPsi+FZmbFGSdcZqq5rp/ZwtwroRSSmVfh99A+6MXv5qqdvkF9WN/LpeZOZmJXmdTgj4osXlZKcmMBDr+/1OhQJk5KuM7SqupH0lESumqfeXCISu8pKfJiN3eHXL2zZT0dPP3fFUAH9cPmZqdy0uJDVNY20dMbWBIFYpaTrDPT0DfKbLc1cNW8KGalju8GeiMhHyU5PZtakzDHZmf7EnMWZk8ZTUerzOpwR9ZVLp9E/GODnb9V6HYqEQUnXGfjdjgN09g5o7I+IxIVyv4+aunYGxtjImc2NHWxt6hjTcxbDVZqXwVXzJrNyXR3HNAg76inpOgOrqhspyBnHkhj/5iQiAsFi+q6+QXY2d3odyhlZubaOjJREPrcwPu4wv++y6XQeH+DJ9fVehyKnoaQrTM0dPby55xA3Li4kISG2vzmJiADvN38eS5cY27v6eGHLfq5fVEBmWrLX4YyKC4tyWDZtAj95cx99A2PrrGS8UdIVpmc3Bntz3ajeXCISJ6Zkj6Mwd9yYKqb/ZXUDfQMB7lzq9zqUUXXf8mkcOHqcX21q8joU+QhKusLgnGNVdSMVfh8lEzK8DkdEZNRU+H1U1raNieHKgYDjsXX1VJT6mDU50+twRtXymfnMnpzJQ6/vJRCI/r+reKWkKwybGo6wt7VLBfQiEnfKS30c7upj7xhowPnau63Ut3VzZwy3iTgVM+P+5dN5t+UYr+5u8TocOQUlXWFYVd1IWnICV12g3lwiEl/K/cEbh6rGQF3XY2vryBufyqfPj89j9dXzp1CQM44VGg0UtZR0ncbx/kFe2Lyfq+ZNiZuiTBGRE6bnZzAhI4UN+6J7+HVDWzev7G7h1ooiUpLi86MtOTGBey4tpbK2neq66E+S41F8/ss8A3/YeZCjxwe4cZEuLYpI/DEzyvy5UT/8+okN9Rhwa0Wx16F46s/Ki8hJT2bFaxoNFI2UdJ3GqupGpmansWz6BK9DERHxRLnfR31bNwePRueomd6BQZ6qbOATcyYxNWec1+F4Kj0libuW+fn9joPsaTnmdTgyjJKuj9By9Divv9PK9YsKSFRvLhGJUydG6WyI0tYRa7Y209bVx13L/F6HEhW+sKyEtOQEHnpdtV3RRknXR3h2YxMBhy4tikhcmzsli4yUxKi9xLhybR3T8jK4SFckAJgwPpWby4p4dmNT1J6djFdKuk7BOcfqmkYWFecwLX+81+GIiHgmKTGBRSW5UXmma1tTBzX1R7h9aYmmhQxxzyXTGAw4fvrWPq9DkSGUdJ3C1qYO3jl4jJsWF3kdioiI58r9PnYf7KSjp9/rUD7g8fV1pCUncJOuSHxA8YR0rp4/lSfW1XP0eHT9ncUzJV2nsLq6kdSkBK6eP8XrUEREPFfmz8U5oqoVQUdPP89t3M91FxaQna6WPsPdd9k0OnsHeEKDsKNGWEmXmV1pZrvNbI+Zfe8ky7PN7AUz22xm283s7iHL/iL03DYze9LM0iL5BkZC78Agv9q8n0+dP5nscfqPLCKysCiX5ESLqn5dz9Q00tM/yJ3L4q8DfTjmFWRz6Yw8fvrmPnoHBr0ORwgj6TKzROCHwFXAXOBWM5s7bLWvAzuccxcCHwP+t5mlmFkB8OdAmXNuHpAI3BLB+EfEKztbONLdr7E/IiIh41ISmVeQHTXF9M45Vq6rY2FxDvMKsr0OJ2rdd9l0Wjp7eW6jBmFHg3DOdFUAe5xze51zfcAvgOuGreOATDMzYDzQBgyEliUB48wsCUgH9kck8hG0uqaRSVmpXHJentehiIhEjQq/jy2NRzje7/1Zk7ffO8ze1q64nLN4Ji4+bwLnT83iQQ3CjgrhJF0FQMOQx42h54b6b2AOwYRqK/At51zAOdcE/AdQDzQDHc65351z1COotbOXV3e3cv3CQvXmEokBYZRHmJn9V2j5FjNbNGx5opltNLNfj17U0anc76N/0LG54YjXobBybR256cl85gLV3X6UE4Ow97Z28fudB70OJ+6Fk3SdLPMYni5/GtgETAUWAP9tZllmlkvwrFhpaFmGmd1x0p2Y3WtmVWZW1draGvYbiLRfbWpiMOC4afHwvFJExpowyyOuAmaEfu4FfjRs+beAnSMc6phQ5s8F8PwSY3NHD7/feZCby4tIS070NJax4Kp5kynyBQdhO6ezXV4KJ+lqBIb2TSjkw5cI7waecUF7gH3AbOATwD7nXKtzrh94BrjoZDtxzj3knCtzzpXl5+ef6fuImFXVjVxYlMN5EzM9i0FEIiac8ojrgEdDx691QI6ZTQEws0LgauDh0Qw6WuWkpzBrUiYbar0tpn9yQwMB57hjiS4thiMpMYF7L53GxvojVHr8dxfvwkm6KoEZZlZqZikEC+GfH7ZOPXAFgJlNAmYBe0PPLzWz9FC91xVE8TfG7fs72HWgUwX0IrEjnPKIj1rn/wB/DQRGKsCxprw0l5q6dgY9qg/qHwzw5IZ6Pj5rIkW+dE9iGItuWlyELyOFB1/TaCAvnTbpcs4NAN8AXiKYMD3tnNtuZveb2f2h1f4ZuMjMtgIvA991zh1yzq0HVgE1BGu9EoCHRuB9RMSq6kZSEhP4rHpzicSKcMojTrqOmV0DtDjnqk+7kygpjxgN5X4fx3oH2Nl81JP9v7T9AK2dvSqgP0PjUhL54kV+Xt7Vwu4DnV6HE7fC6tPlnFvjnJvpnJvunPuX0HMrnHMrQr/vd859yjl3gXNunnPusSHb/oNzbnbo+Tudc70j81bOTd9AgF9t2s8n504iJz3F63BEJDLCKY841ToXA9eaWS3By5KXm9ljnES0lEeMBq+HX69cW0eRbxyXzYztP+eRcOfSEsYlJ/LQ63u9DiVuqSN9yB93t9DW1ceNKqAXiSXhlEc8D9wVuotxKcG7rJudc3/jnCt0zvlD273inDvpjUDxZEr2OApzx3lSTP/OwU7W72vj9iUlurv8LORmpHBLRRG/2tTE/iM9XocTl5R0hayuaSRvfCqXzdC3J5FYEWZ5xBqCNah7gB8DX/Mk2DGkwu+jsrZt1O+Ee2xdHSlJCdxcppm4Z+vLl5TigJ++qUHYXlDSBRw+1svLO1u4fuFUkhL1RyISS8Ioj3DOua+Hll/gnKs6yWv80Tl3zWjHHq3K/D4OHetj36GuUdvnsd4Bnqlp4poLpuDLUAnI2SrMTeez86fw5IZ6Oro1CHu0KcMAnt+8n4GA40bdtSgicloVpaPfr+u5jU0c6x3QnMUIuG/5dLr6BnlsfZ3XocQdJV0ELy3OK8hi9uQsr0MREYl60/PH48tIGbXh1845Vq6tY15BFguKckZln7FszpQsls/M52dv7YuKkU7xJO6Trl0HjrKt6Sg3LdJZLhGRcJgZZSW5VNWNzpmuytp2dh/s5M6lJQRbPsq5un/5dA4d62N1TaPXocSVuE+6Vlc3kpxoXLtAdy2KiISrotRH3eFuWo4eH/F9rVxXR2ZaEtdeqON0pCyd5uPCwmx+/PpezxrdxqO4TroGBgM8u3E/l8+eqMJMEZEzUO4P9esa4bquls7jvLitmc8vLmJciuYsRsqJQdi1h7t5afsBr8OJG3GddL3+biuHjvVy02LdfiwicibOn5pFekoilSPcJPXpygb6Bx13LC0e0f3Eo0+dPxn/hHQe1CDsURPXSdeq6kYmZKTwsVnqzSUiciaSEhNYVJw7osOvBwYDPL6+nktn5DEtf/yI7SdeJSYYX7lsGpsbO1i797DX4cSFuE26jnT38YcdLVy3oIBk9eYSETlj5X4fuw4cpaNnZPo9vbyrheaO49yhOYsj5sZFheSNT+HB1zQaaDTEbbbxwub99A0GNPZHROQslZfm4hzU1I3M2a7H1tUxJTuNK2ZPHJHXF0hLTuTui0t57Z1Wduz3Zoh5PInbpGtVdSNzpmRx/tRsr0MRERmTFhblkpxoI1JMv7f1GG+8e4jbKoo1KWSE3bGkhIyURB56/T2vQ4l5cfkv+d2DnWxu7ODGRTrLJSJytsalJDKvIHtEiukfX19PUoLxZxW60WmkZacnc2tFMS9saaaxvdvrcGJaXCZdq2oaSUowPrdQSZeIyLko9/vY0tgR0c7mPX2D/LKqgSvnTWZiZlrEXldO7cuXlmLAw29oEPZIirukazDgeG5jEx+bNZG88alehyMiMqaV+330DQbY3HAkYq/5/OYmjh4f4K5l/oi9pny0KdnjuG5BAU9VNtDe1ed1ODEr7pKuN95t5eDRXm5SAb2IyDkrKwkOv66KUDG9c45H19Yxa1Im5f7ciLymhOe+5dPo6R/k0bUahD1S4i7pWl3TRG56MpfPnuR1KCIiY15uRgozJ41nQ4TqujY1HGH7/qPcsUxzFkfbzEmZXDF7Io+sraWnT4OwR0JcJV0dPf28tP0A1144lZSkuHrrIiIjptzvo6auPSIz/FauqyMjJZHrVXPrifuWT6etq49fVjd4HUpMiqvM4zdbmukbCGjsj4hIBFWU+ujsHWBn87n1eWrr6uPXW5q5YVEh41OTIhSdnIlyfy6LinP48Rt7GRgMeB1OzImrpGtVdQMzJ41nXkGW16GIiMSME8OvK8+xX9cvqxroGwhw5zJ1oPeKmXHf8uk0tPWwZpsGYUda3CRd77Ueo6b+CDctLlSdgIhIBE3NGUdBzrhzSroGA47H1texpNTHzEmZEYxOztQn50xiWn6GBmGPgLhJup6paSQxwfjcAtUJiIhEWkWpjw372s/6Q/r1d1ppaOvRWa4okJBg3HfZNLbvP8pbezQIO5LiIukaDDieqWnishl5TMxSoz0RkUgr9/s4dKyX2sNn19F85bo68jNT+dTcyRGOTM7G5xYWMDEzlRWvaTRQJMVF0rX2vcM0dxxXAb2IyAipKA321DqbkUANbd28uruFW8uLdGd5lEhNSuRLl5Ty5p5DbGvq8DqcmBEX/7pXVTeQlZbEFXM0qV5EZCRMzx9PbnryWQ2/fnx9PQlm3LqkeAQik7N125JiMlOTdLYrgmI+6eo83s+L2w9w7YKppCUneh2OiEhMMjPK/L4zLqY/3j/I01UNfHLOJKZkjxuh6ORsZKUlc9vSYtZsbab+LC8bywfFfNK1Zmszx/sD3Lio0OtQRERiWoXfR93hblqOHg97mzVbm2nr6lMBfZT60kcVKI0AAAv/SURBVMWlJCUk8OM39nodSkyI+aRrdXUT0/MzWFCU43UoIiIxrbz0RL+u8OcwrlxXx7T8DC6aPmGkwpJzMCkrjesXFvB0VQOHj/V6Hc6YF9NJV+3/3969B8dVlnEc/z4JiU1ammSxlTRNmlAqapsWSpIWUVQELW21KlcVHBxHdAQHHB1FHf9Q/9DRGZUZGbFSRARv01ZFrEId0UKlF1MKpS0dS9JL0gQM6Y2mbZLm8Y9dIKZpum1zztlz9veZyTS7ezb7vGny7i973n3erkOs29HN1erNJSISuOmTxlNSVJj1Kcbn2vfz9K593DhH+yzmsk9fdh69xwb4hTbCPmOJDl3LN7RRYPCRi3RqUUQkaEWFBcyeUp715tcPrtnJmKICrr5Yc3QuO3/iOK5865t44Kkd9PT2R11OrCU2dA0MOMs2tPOOaRM4t0y9uUREwtBYm2Jr5wEOHOkb8bj9h/v4w8Z2PnRhFWUlRSFVJ6frM++ayr6ePn67Xhthn4nEhq41rS/Tvu8wV89WB3oRkbA01aZwh+adI6/rWtrcxpE+7bMYFxdPqaCpNsXPVrXwzO592h7oNCU2dC1rbufsN5zF+6eru7GISFguqqngrAIbsUnqwIDz4JqdzK4pZ/qkshCrkzPxhSvfTNcrvSy6ezXv/N7jfGfFVgWwU5RV6DKzeWa2zcy2m9mdw9xeZmZ/MrNnzGyzmX1y0G3lZrbUzJ43s61mdsloDmA4h47285fnOlg4q1K9uUREQlRSXMiMqrIRF9P/64WXae06pFe5YuaSqeew/utX8P1rZnL+xHEsebJVAewUnXWyA8ysELgbuBJoA9ab2cPuvmXQYbcCW9z9A2Y2AdhmZg+5ey9wF/BXd7/GzIqB0tEfxv/7y3Od9PQe4xotzhQRCV1TXYr7V+/gSN+xYf/w/eWaHaTGFnPVjMoIqpMzUVZaxLUN1VzbUM3+nj4e29LJnzd1sOTJVn66qoXJFSUsqK9kfn0lMyeX6V2pQ5w0dAFNwHZ3bwEws98Ai4DBocuBsy393R0HdAP9ZjYeuAy4GSATwnpHrfoTWNq8m7o3jmV2TUXQDyUiIkM01qZYvKqFZ9v205Tp3fWqjv2HWbnlRW65bKrORMTc4AC2r6eXx7a8yAoFsBFlE7qqgMFvV2gD5gw55sfAw8Ae4GzgencfMLPzgP8CPzezWUAzcLu7Hzrjyk9gd3cPa1q6+dL73qz/YBGRCDRMyWx+vaP7uND167W7cODj2mcxUcpLi7muoZrrThLAFsyspL4qfwNYNqFruO/M0JO27wc2ApcDU4GVZvZE5uvPBj7v7mvN7C7gTuAbxz2I2S3ALQA1Naf/y7h8Qztm8GFt+yMiEomKscVMmziOda3d3Pqe16/v7R/gV+t2c/kFE6lOBb7SRCKiAHZi2YSuNqB60OXJpF/RGuyTwHc9vYJuu5m1Am8BdgFt7r42c9xS0qHrOO6+GFgM0NDQcFor8dydZRvaePvUc6gq18apIiJRaaxL8aeNezg24BQWpJ9UH93cSdcrR7lRC+jzxskCWHWqhPn1lSyoz48Alk3oWg9MM7M6oB24AfjYkGN2Ae8FnjCzNwEXAC3u3mVmu83sAnffljlmCwFZv2Mvu7p7+MKV04J6CBERyUJTbYpfrd3F850HXmsL8cs1O6lOlfCuaRMirk6iMFwA+/OzHSx5opWf/jM/AthJQ5e795vZbcCjQCFwn7tvNrPPZm6/B/g2cL+ZbSJ9OvIr7t6V+RKfBx7KvHOxhfSrYoFY2rybscWF6s0lIhKx1za/bu1m+qQytnUeZF1rN1+96i0UFCTvyVROTb4GsGxe6cLdVwArhlx3z6DP9wDvO8F9NwINZ1BjVnp6+1mxqZMFMyspLc5qWCIiEpCq8hKqyktYv2MvN19ax4NrdlJ8VgHXNlSf/M6SV44LYJtfTLehSGAAS0w6eXRzJ68c7edqLaAXkUHMbB7pfoGFwL3u/t0ht1vm9vlAD3Czu28ws2rgAeBcYABY7O53hVp8zDXWVrD6hZc5eKSP5RvaWDizktTY4qjLkhxWXlrMdY3VXNc4cgBbWD+JGVXjYxfAEhO6ljW3U5MqpbE2dfKDRSQvZNnc+SpgWuZjDvCTzL/9wBczAexsoNnMVg65r4ygsS7FHzbu4a6//YdDvcf4xCW1UZckMZLEAJaI0LVn32FWv9DF7e+dprUCIjJYNs2dFwEPZN59vSazdVmlu3cAHQDuftDMtpLuW6jQlaWmzB/BS1a3Ul9VxqzJ2mdRTs/JAlhNqvS1U5C5HMASEbp+/3Q77ujUoogMlU1z5+GOqSITuADMrBa4CFiLZO38ieOoKC1ib08fN82dkrNPhBIvwwWwRzZ1cO8TLdzzzxdyOoDFPnS5O0ub25h7XkrN9kRkqGyaO494jJmNA5YBd7j7gWEfZJSaOyeNmTGn7hyeanmZD8yaFHU5kkBxC2CxD10bdu2ltesQn3v31KhLEZHck01z5xMeY2ZFpAPXQ+6+/EQPMhrNnZPqW4ums/9wHyXF2mdRgjU4gO091JvZjLszpwJY7EPX0uZ2SosLmV+v3epF5DjZNHd+GLgts95rDrDf3Tsy72pcAmx19x+EWXSSTBw/honjx0RdhuSZirHFXN9Yw/WNNSMGsIUzK5k+KbwAFuvQdaTvGI88s4d5M85l7BtiPRQRCUCWzZ1XkG4XsZ10y4hXGzhfCtwEbDKzjZnrvpbpWygiMXGiAPazCAJYrJPKY1te5ODRfq65WAvoRWR4WTR3duDWYe73JMOv9xKRmMomgC2Y+eopyNF/t22sQ9cfn26nqryEuXXnRF2KiIiIxMhwAeyRZztYvKqFx59/ib/ecdmoP2asQ9cPb7iQnV096s0lIiIip21oANuz/3AgjxPr0DV+TBH1arYnIiIio6RibDEVAW1XVRDIVxURERGR/6PQJSIiIhIChS4RERGRECh0iYiIiIRAoUtEREQkBApdIiIiIiFQ6BIREREJgUKXiIiISAgUukRERERCoNAlIiIiEgJz96hrOI6Z/RfYmeXhbwS6AiwnV+TDOPNhjKBxDmeKu08IspiwaP4alsaZHPkwRjj1cWY1h+Vk6DoVZvZvd2+Iuo6g5cM482GMoHHK6/Lle6RxJkc+jBGCG6dOL4qIiIiEQKFLREREJARJCF2Loy4gJPkwznwYI2ic8rp8+R5pnMmRD2OEgMYZ+zVdIiIiInGQhFe6RERERHJerEOXmc0zs21mtt3M7oy6niCY2X1m9pKZPRd1LUExs2oze9zMtprZZjO7PeqagmBmY8xsnZk9kxnnN6OuKShmVmhmT5vZI1HXkqs0fyWD5q/kCXL+im3oMrNC4G7gKuBtwEfN7G3RVhWI+4F5URcRsH7gi+7+VmAucGtC/y+PApe7+yzgQmCemc2NuKag3A5sjbqIXKX5K1E0fyVPYPNXbEMX0ARsd/cWd+8FfgMsirimUefuq4DuqOsIkrt3uPuGzOcHSf+wV0Vb1ejztFcyF4syH4lbVGlmk4EFwL1R15LDNH8lhOavZAl6/opz6KoCdg+63EYCf9DzjZnVAhcBa6OtJBiZl603Ai8BK909ieP8EfBlYCDqQnKY5q8E0vyVCIHOX3EOXTbMdYlL3fnEzMYBy4A73P1A1PUEwd2PufuFwGSgycxmRF3TaDKzhcBL7t4cdS05TvNXwmj+ir8w5q84h642oHrQ5cnAnohqkTNkZkWkJ6yH3H151PUEzd33Af8geetdLgU+aGY7SJ8yu9zMHoy2pJyk+StBNH8lRuDzV5xD13pgmpnVmVkxcAPwcMQ1yWkwMwOWAFvd/QdR1xMUM5tgZuWZz0uAK4Dno61qdLn7V919srvXkv6d/Lu73xhxWblI81dCaP5KjjDmr9iGLnfvB24DHiW9cPF37r452qpGn5n9GngKuMDM2szsU1HXFIBLgZtI/1WxMfMxP+qiAlAJPG5mz5J+0l3p7mqpkIc0fyWK5i/JmjrSi4iIiIQgtq90iYiIiMSJQpeIiIhICBS6REREREKg0CUiIiISAoUuERERkRAodImIiIiEQKFLREREJAQKXSIiIiIh+B/s6TGuZbaxLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0000\n",
      "Test Loss: 0.0089\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAE/CAYAAAB8VnbnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xt83Hd95/vXZ0Z3aXSzLrY1Is5FjmNiG4IbstCkhdA2gUK63e0u2QJtz3JCFuiy5/S0zfZ0od1LT9ttu4U9PJKmlO3S9sBS2i6hG0I3aSHQJSEOSXyJc3GciyXrNrI90ug2kuZ7/vj9fvJE1mU0mvnNb+T38/HQI9LMT/P7ypjxR9/v5/v+mnMOERERESmvWKUHICIiInI5UNElIiIiEgIVXSIiIiIhUNElIiIiEgIVXSIiIiIhUNElIiIiEgIVXSIiIiIhUNF1GTCzTN5Hzsxm877+6S287mNm9oECrmv37/mXxd5LRGSzKvXeZ2b7zGyx2NeX7aum0gOQ8nPOtQSfm9krwIedcw+HOIR/CswA7zGzHc65ibBubGY1zjm9+YlchiLw3ifyOprpEswsbmb/xsxOm1nKzP7MzNr955rN7Etmds7MLpjZ42bWYWa/C/wA8Dn/t8bfXecWPwP8PvAScOeKe+8xs6/6903lv46ZfdTMnjOzKTM7ZmYHzKzBzJyZJfOu+5KZ/ar/+W1mdsr/eUaBe82s28y+bmbj/s/xVTPblff9XWb2BTMbMbPzZvbf/MdPmdmP5F3XYGZpM7tuC3/cIhIRIbz3rXbPRjP7rJkNm9mgmf1HM6v1n9tpZg/595sws7/N+75/43/PpJmdNLObS/lnIeFQ0SUAvwj8KPCDQBJYAP6T/9yH8WZE+4Au4ONA1jn3C8ATeL85tvhfX8LMBoCbgP8P+DPgQ3nP1QJfB04CbwD6gb/wn/sg8Mt4RVor8I+B8wX+PHuAWv/1/iXe3/P7/Htc6V/zn/Ku/2+AAfuAXuCz/uNfAPKXEO4AXnDOnSxwHCISbWV771vHrwMHgQPAW4AfBn7Jf+6Xgef9++0Cfg3AzA4BPwe8CWgD3gMMbvK+EgEqugTgI8A9zrmzzrk5vDeFf2pmhvcm1A1c7ZxbdM494Zyb3sRr/wzwPefcS3iF1+G8maIfxCuofsU5N+Ocm3XO/S//uQ8Dv+Gce8p5nnfOFfomMw/8O+dc1n/NUefcV/3P08D/A/wQgJldCdwMfNQ5d8H/nkf91/kC8BNm1uR//UHgTzbxs4tItJXzvW8tPw18yjmXcs6NAv8e770F/567gTeseC9aBBqB/UDcOXfaOfdyCcYiIVPRdZnz31z6gQf9Ke0LwFN4fzd2AH8EfAv4ij8V/htmFt/Ea38Qb4YL/03iMbxCDP++Lzvncqt8ez/ecmQxRpxzC3njSJjZ583sNTObBP4G7zfJ4D5jzrmplS/inHsF78/iDjPrBt4JfKnIMYlIhJTzvW+De+4EXs17+FW82TSA/wCcBf7Ob2/4PwGccyeAe/znx/xl0N6tjEUqQ0XXZc4554Ah4J3Oufa8jwb/N7F559wnnXP7gFuAnwLeH3z7Bi//DrwlvV/z+6VGgEPAB8wsBpwB9vifr3QGuHqVx7N4vw025T22c+WPteLre/CWDn7AOdeKt5xgeffpMbMWVvdf8ZYY3w/8rXNubI3rRKSKlPm9b717jgBX5D38Bn8cOOfSzrlPOOeuAP4R8Ktm9nb/uf/qnHsbcBXQgDdDJlVGRZeA1+/0m2bWD2BmPWb2Xv/zd5nZfr8wmsSb5l7yv28U7w1gLT8D/DXwRrxehDfhFV2dwK3Ad4Ap4N+ZWZPfYPo2/3s/B9xjZofMs9fMkv6s2DHgp/0m2PcC/2CDny+Bt3vygpl1Ab8aPOHPvj0K/L9m1mZmdWZ2S973fgVvGfRf4C03isj2Ua73PvzXaFjxYcAXgU+Z2Q4z6wH+b+BP/evfZ2ZX+tel/fst+eP4ITOrB2b9j6XV7ypRpqJLAH4beBj4WzObAv4XcIP/XB/wVbzi6DjwIPBl/7n/BHzI3/H32/kv6M8c/SPgM865kbyPU3hLdD/jLwG+G68QGwReA34SwDn3J8Dv4RU9k/5/2/2X/zheDMV54B/iFXbr+R285cQJvELvwRXP34nXeP8i3m+h/yJ4wl92/Jr/5/DABvcRkepS8ve+PHEuFkjBx9uBTwLPAieAp4G/98cBcB3wTf+ejwK/45x7DK+f63eBFDAMtPivI1XGvNlOEVmLmf0G0OOc+3ClxyIiItVL4agi6/Ab6H8W+IkKD0VERKqclhdF1mBmHwdeAf7cOfe9Cg9HRESqnJYXRUREREKgmS4RERGREKjoEhEREQlBJBvpu7q63J49eyo9DBEJyZNPPplyznWX47XN7Dbg03hb+D/nnPvNFc+b//y78fLcftY5930zuxbvXM7AVcAnnXO/v9799P4lcvkp9D0skkXXnj17OHLkSKWHISIhMbNXN76qqNeN4x1g/iN4WXBPmNkDzrln8y67HRjwP94K3Au81Tn3PF6gb/A6Q8BfbXRPvX+JXH4KfQ/T8qKIbGc3Aqf8A4KzeMG8d6y45g7gC/7B6o8B7Wa2a8U1twIvOefKUhyKyOVBRZeIbGd9eOdrBga5eLjwZq55P97xLSIiRVPRJSLbma3y2MqcnHWvMbM64H3An695E7O7zOyImR0ZHx8vaqAisv2p6BKR7WwQ6M/7Ogmc3eQ1twPfd86NrnUT59z9zrnDzrnD3d1l2Q8gItuAii4R2c6eAAbM7Ep/xur9XHpw+QN4hxebmd0EpJ1zw3nP34mWFkWkBCK5e1FEpBScc4v+cU7fwIuM+Lxz7oSZ3e0/fx/wIF5cxCm8yIifC77fzJrwdj5+JOyxi8j2o6JLRLY159yDeIVV/mP35X3ugI+t8b0zwI6yDlBELhtaXhQREREJgYouERERkRCo6BIREZENLSzl+PtTqUoPo6qp6BIREZENff34CD/9ucc5PZ6p9FCqloouERER2dDwhVkAhvz/yuap6BIREZENTUxnARibnK/wSKqXii4RERHZUGrKK7ZGp+YqPJLqpaJLRERENjSe8YouzXQVT0WXiIiIbCiV8ZcXNdNVNBVdIiIisqGUP9M1qpmuoqnoEhERkXXlco5z05rp2ioVXSIiIrKu8zNZlnKOxto4o5PzeEeWymap6BIREZF1BXER+3YlyC7mmJxdrPCIqpOKLhEREVlXEBexf1croNiIYqnoEhERkXUFcRH7d3tFl2IjiqOiS0RERNYVxEUsz3RNaqarGCq6REREZF2pzDy1cWOgNwHA2JRmuoqhoktERETWlZqaZ0dzPS31NbTU12imq0gqukRERGRdE9NZuhJ1APQk6hnXTFdRVHSJiIjIulKZebpa6gHoaa3XTFeRVHSJiIjIulJTeUVXokE9XUVS0SUiIiJrcs6RymTZ0eItL/b6M11Kpd88FV0iIiKypsm5RbJLObr9ma7e1gbmF3NMzimVfrNUdImIiMiaUn4warC82J3w/jumvq5N27DoMrPPm9mYmR1f43kzs8+Y2SkzO2pmN6x4Pm5mT5nZX5dq0CIiIhKO4AigrryZLoBRpdJvWiEzXX8M3LbO87cDA/7HXcC9K57/BHCymMGJiIhIZQWHXedHRgCM6fzFTduw6HLOPQqcW+eSO4AvOM9jQLuZ7QIwsyTwHuBzpRisiIiIhGvl8mKPZrqKVoqerj7gTN7Xg/5jAL8P/BKQK8F9REREJGSpqXliBh1N3kxXS30NzXVxzXQVoRRFl63ymDOzHwfGnHNPFvQiZneZ2REzOzI+Pl6CYYmIiMhWjWeydDbXEY9d/Oe+t7WBMc10bVopiq5BoD/v6yRwFng78D4zewX4EvBOM/vTtV7EOXe/c+6wc+5wd3d3CYYlIiIiW5WfRh/oTtRrpqsIpSi6HgA+5O9ivAlIO+eGnXP/2jmXdM7tAd4P/K1z7gMluJ+IiIiEZLWiq7e1QT1dRajZ6AIz+yLww0CXmQ0CnwJqAZxz9wEPAu8GTgEzwM+Va7AiIiISrolMlive0PS6x3r8mS7nHGardRnJajYsupxzd27wvAM+tsE13wS+uZmBiYiISOWtNdM1t+Cl0rc11lZoZNVHifQisq2Z2W1m9rwf4HzPKs+vGfBsZu1m9hUze87MTprZPwh39CKVNZNdZCa7RFfi9UVXT6v39bj6ujZFRZeIbFtmFgc+ixfivB+408z2r7hsvYDnTwMPOef2AYdQ0LNcZlJTXjDqjua61z3ek1BWVzFUdInIdnYjcMo5d9o5l8XbSX3HimtWDXg2s1bgFuCPAJxzWefchTAHL1Jp40EwamLl8qJS6YuhoktEtrP1wps3uuYqYBz4L/75sZ8zs+bVbqKcQdmugjT67paVy4ua6SqGii4R2c5WDW8u8Joa4AbgXufcm4Fp4JKeMFDOoGxfK48ACiyn0qvo2hQVXSKyna0V3lzINYPAoHPucf/xr+AVYSKXjYmM39PVUnfJcz2tDYxqeXFTVHSJyHb2BDBgZleaWR1eUPMDK65ZK+B5BDhjZtf6190KPBvayEUiIJWZp72pltr4peVCT6KesUkVXZuxYU6XiEi1cs4tmtnHgW8AceDzzrkTZna3//xGAc8/D/yZX7CdRuHPcplJZeYv2bkY6Glt4Oig9pZshoouEdnWnHMP4hVW+Y/dl/f5mgHPzrmngcNlHaBIhKWmspf0cwV6E/WMTiqVfjO0vCgiIiKrSmXmL4mLCPS01jO3kGNqfjHkUVUvFV0iIiKyqvHM/CVxEYFePzZCfV2FU9ElIiIil5hfXGJqbpGuVXYuAnT7M2CKjSicii4RERG5RBAXsWZPVxCQqtiIgqnoEhERkUusFYwa6NFM16ap6BIREZFLBEXXasGo4KXSN9XFdRTQJqjoEhERkUukptZfXjQzelsbdOj1JqjoEhERkUuMB4ddrxEZETyn5cXCqegSERGRS6Qy87TU19BQG1/zGs10bY6KLhEREbnERCa7ZlxEoCdRz+jkPN7BDrIRFV0iIiJyiVRmfs1+rkBvaz2zC0tklEpfEBVdIiIicolUZn7NnYuBnoSf1aW+roKo6BIREZFLpDJrH3Yd6GkNsrrU11UIFV0iIiLyOotLOc7PFFB0+TNdY1Oa6SqEii4RERF5nXPTWZyDrnXiIsDr6QIY1UxXQVR0iYiIyOuk/HMXuzfo6Wqpr6GxNq6ZrgKp6BIREZHX2ejcxYCXSl+vma4CqegSERGR17l47uL6RRd4fV2a6SqMii4RERF5nYszXesvL4K3g1G7FwujoktERKpCdjHHy6npSg/jspDKZKmvidFSX7Phtd5RQEqlL4SKLhERqQp/8f1BfuT3vsVwerbSQ9n2UlNeGr2ZbXhtT6KemaxS6QuhoktERKrCy6lpFnOOb7+QqvRQtr3xzPyGcRGB3lZldRVKRZeIiFSF4bTXN/Toi+MVHsn2N5HJbhgXEehJKKurUCq6RESkKoz4y4p/fypFLqf+oXIq5LDrQI8/0zWuma4NqegSEZGqMJyeo6kuzvmZBU6cnaz0cLatXM4xMZ3d8LDrQI9S6QumoktERCIvl3OMTs7x7gO7AC0xltOF2QWWcq7gma5EkEo/qZmujajoEhGRyJuYzrKw5DjQ18b+Xa18W0VX2RSaRh8wM3pa6xnV8uKGVHSJiEjkjfhN9DvbGrh5bxdPvnqeaUUUlEVqanNFF0BvokHLiwVQ0SUiIpEXZHPtamvgloFuFpYcj788UeFRbU+paf+w60RhPV0A3a31aqQvgIouERGJvJHJizNdb7mig/qaGN9+UXld5aCZrvJR0SUiIpE3nJ6jJmZ0NdfTUBvnrVftUNFVJqnMPDUxo7WhtuDv6WlVKn0hVHSJiEjkjaTn6G1tIBbzjqW5ZaCLU2MZzl7QkUCllsrMs6OlbvnPuhC9io0oyIZFl5l93szGzOz4Gs+bmX3GzE6Z2VEzu8F/vN/M/s7MTprZCTP7RKkHLyKyETO7zcye99+j7lnl+VXfw/znXjGzY2b2tJkdCXfkkm84Pcuutoblr28e6AbgO5rtKrlUJruppUXwlhcBxUZsoJCZrj8Gblvn+duBAf/jLuBe//FF4Becc9cBNwEfM7P9xQ9VRGRzzCwOfBbvfWo/cOcq70NrvYcF3uGce5Nz7nC5xytrG0nPsTOv6Nrb20JPol55XWWwmTT6QBCQOjalma71bFh0OeceBc6tc8kdwBec5zGg3cx2OeeGnXPf919jCjgJ9JVi0CIiBboROOWcO+2cywJfwnvPyrfqe1jYA5W1OecYTs+9bqbLzPjBgS4dCVQGqaliii7NdBWiFD1dfcCZvK8HWVFcmdke4M3A42u9iJndZWZHzOzI+Lh+cxGRktjw/WmDaxzwN2b2pJndVbZRyrouzCwwv5hjZ1vj6x6/ZaBbRwKVmHOO1HSWrk3ERYCXSt9QG1NP1wZKUXSt1mm3/GuHmbUAfwH8K+fcmv/PcM7d75w77Jw73N3dXYJhiYis//5UwDVvd87dgLcE+TEzu2XVm+iXxrIa9oNR82e6AN5+TRegI4FKaWp+kexijq7mzc10mRm9rQ2MKatrXaUougaB/ryvk8BZADOrxSu4/sw595cluJeIyGas+f5UyDXOueC/Y8Bf4S1XXkK/NJbXyKS3Q3HniqKrO1GvI4FKbDmja5MzXQA9iXrNdG2gFEXXA8CH/B1ANwFp59ywmRnwR8BJ59zvleA+IiKb9QQwYGZXmlkd8H6896x8a72HNZtZAsDMmoEfBVbdxS3ltdZMF6AjgUoslfHS6Dfb0wVeX5dS6ddXSGTEF4HvAtea2aCZ/XMzu9vM7vYveRA4DZwC/hD4qP/424EPAu/0t1s/bWbvLv2PICKyOufcIvBx4Bt4m3m+7Jw7UeB7WC/wHTN7Bvge8D+ccw+F+gMI4O1cjBl0r1II3HyNdyTQ915eb7+XFGqzh13n00zXxmo2usA5d+cGzzvgY6s8/h1W75UQEQmNc+5BvMIq/7H78j5f6z3sNHCo7AOUDQ2n5+hJNFATv3Se4PAe70igR18c5x37eiowuu1lK0VXb2sD034qfUv9huXFZUmJ9CIiEmkrM7ry6Uig0kplssQMOpuL6+kCGNNs15pUdImISKStTKNfSUcClU4qM09ncx3xTRwBFOj1s7pGldW1JhVdIiISWUEw6lozXaAjgUopNTXPjk3GRQSWZ7qUSr8mFV0iIhJZU/OLzGSX1p3pCo4E+vYpFV1blcrMFxUXAUqlL4SKLhERiawRPy5iZRp9vuBIoO+8OK4jgbaomMOuA60NNdTXxDTTtQ4VXSIiElnrZXTl05FApVHMYdeBIJVePV1rU9ElIiKRNZL20+hb1y+6dCTQ1s1kvaXcYosugN7Wes10rUNFl4iIRFYw09W7QdGlI4G2bmI5jb64ni6AnkSDerrWoaJLREQiayQ9R1dLPXU1G/9zdfOAdyTQTFZHAhVjfAvBqIGe1noder0OFV0iIhJZw+m5Dfu5AjcPeEcCPX5aRwIVY/mw660UXYkGMvOLOgtzDSq6REQkstZLo18p/0gg2bzlw66LjIwAr6cL0GzXGlR0iYhIZG2URp9PRwJtTXDuYrHhqODNdAE6+HoNKrpERCSSpucXmZxbLHimCy4eCTSc1pFAm5XKzNPWWFtQ/9xaNNO1PhVdIiISSSOThWV05fvBAS86QrNdmzeRyW5p5yJcnOnSoderU9ElIiKRtJxG37p2Gv1K1/Ym6E7Uq+gqwvgWglEDrY1eKr2WF1enoktERCKp0DT6fGbGzToSqChbSaMPmFlFYiOODl6oilBWFV0iIhJJy2n0myi6QEcCFSs1Nb/l5UWA3kRDqDNdSznHP/vDx/n0wy+Gds9iqegSEZFIGk7P0dFUS0NtfFPfpyOBNm9+cYnJucUtz3RB+AGpL41nyMwv8urETGj3LJaKLhERiSQvo6vwfq5Ad6Ke63a18h31dRVs+QigRAmKrpCPAjo2mAbgzHkVXSIiIkXZTBr9SrcMdHHk1XM6EqhAqRIcARTobQ03lf7YkFd0nb0wy1LE+/hUdImISCSNTBaeRr+SjgTanFIcdh3oSYSb1XXcL7oWllzkd02q6BIRkciZW1ji3HSWXa3FFV06EmhzSnHYdaC3NbysrqWc48TZSa7ubgbgzLloLzGq6BIRkcgJZiyKnenSkUCbU8rlxR4/lX40hJmu0+MZZheWuP36XQAMno/2SQQqukREJHIuZnRtvpE+cPM1OhKoUKmpLM11cRrrNrdTdDW9IabSHz/rLS3+2Bt3Yhb9ZnoVXSIiEjnLafRFznQB3LxXRwIVKpWZL8nORfBS6etqYqH0dB0bnKShNsZ1uxL0Jho00yUiIrJZwyUounQkUOFKkUYfMDN6W+vDmekaSnPdrlZq4jGSHY3q6RIREdmskfQsiYYaWuprin4NHQlUuFIcdp2vJ9HAaJmzunI5x4mzaQ70tQHQ39mkmS4REZHN2kpGVz4dCVSYVGaeHSWa6QK8ma4yn4V4OjXNdHaJ6/2iK9nRyHB6loWlXFnvuxUqukREJHK8jK7im+gDOhJoY4tLOc7NZEu2vAjhpNIH+VzLM10dTeTcxX7AKFLRJSIikTOcnis6oyufjgTa2LmZLM5BdymXF1vrmZpfLOuJAMeG0tTXxBjoaQEg2ekV6VHu61LRJSIikZJdzJHKzG+piT6fjgRaX2oqSKMv7UwXUNbZrmN5TfTgzXRBtGMjVHSJiEikjE3N4Rwl6ekCHQm0keVg1BJFRoDX0wWU7VieXM7x7NnJ5aVF8P6+xGMW6WZ6FV0iIhIppcjoyqcjgdZXyjT6wPJRQGXK6nplYprM/OLriq6aeIydrQ1aXhQRqRQzu83MnjezU2Z2zyrPm5l9xn/+qJndsOL5uJk9ZWZ/Hd6oL2+lSKPP11Ab58YrO5XXtYZSHnYdCA69LtdM1zG/if76vKILoL+zUTNdIiKVYGZx4LPA7cB+4E4z27/istuBAf/jLuDeFc9/AjhZ5qFKnlLPdIEXHaEjgVaXysxTVxPbUibaSm2NtdTVxBgv00zX8aE0dTUxBnpbXvd4sqNJPV0iIhVyI3DKOXfaOZcFvgTcseKaO4AvOM9jQLuZ7QIwsyTwHuBzYQ66GI++MM7U3EKlh1ESw+k5muritDaUrgjQkUBrG8/M091Sj5mV7DXNjJ5EfVlnuq7bmaA2/voypr+jidHJeeYXl8py361S0SUi21kfcCbv60H/sUKv+X3gl4Dopi0Cr03M8KHPf48vfPfVSg+lJEYmZ9nV1lDSIkBHAq0tVeI0+kBva0NZerpyOceJoclLlhbBC0gFGIroEqOKLhHZzlb7V3vleTCrXmNmPw6MOeee3PAmZneZ2REzOzI+Hn6z9ndPe4XEM2cuhH7vcvDS6EvTzxXQkUBrS02V7tzFfOWa6Xr13AxTK5roA/2dXmxEVPu6VHSJyHY2CPTnfZ0EzhZ4zduB95nZK3jLku80sz9d7SbOufudc4edc4e7u7tLNfaCPeZHIRwdTId+73IYSc+VtJ8rcPNAl44EWkUpD7vOV66ZrrWa6MFrpIfoZnWp6BKR7ewJYMDMrjSzOuD9wAMrrnkA+JC/i/EmIO2cG3bO/WvnXNI5t8f/vr91zn0g1NEXwDnHY6cniMeMkck5xsrUQxOWxaUcY1PzJcvoyhccCfTtU4qOCORyjnPTWboSpV9e7E7UMzW3yGy2tP1Vx4fS1MVj7O1NXPJcT6KB2rhx5lyVznSZ2efNbMzMjq/x/JrbrTfaqi0iUk7OuUXg48A38HYgftk5d8LM7jazu/3LHgROA6eAPwQ+WpHBFum1czMMp+d4z4FdwMVZgGqVymRZyrmyzHT1JBq4blcr335BfV2B9OwCiznHjubyzHQBJT/4+thgmn27EtTVXFrCxGNGX3sjg1U80/XHwG3rPL/qdusCt2qLiJSVc+5B59xe59zVzrn/4D92n3PuPv9z55z7mP/8AefckVVe45vOuR8Pe+yFeOz0BAD/2w9eScyqf4kxiHQox0wX6EiglcqRRh+4mNVVuiVG5xzHz6ZXXVoMeLERVTrT5Zx7FFjv7IS1tlsXslVbRES24LHT59jRXMehZBvX9LRU/UzXckZXa2kb6QM6Euj1xpfT6MuzexFKO9P12rkZpuZWb6IP9Hc2MhTRma5ShKCstd16tcffWoL7Lfv1r53gWTVEikTS/t2tfOq9b6z0MLa1oJ/rpqt2YGYc6GvnWy+M45wradxCmC6m0Zdnpiv/SKB37Ospyz2qScpPo+8u0+5FKO1MV/BLxXpFV7KjiVQmy0x2kaa60mW9lUIpGunX2pJdyFbtiy9S4S3XIiLVJujnuumqTgAO9beRyswvFy7VaGRyjvqaGO1NtWV5/eBIoO8orwvw4iKgtOcuBtqbaqmLx0q6uePYUJrauF2SRJ8vylldpSgB19puXbfG46tyzt0P3A9w+PDhgkJU9Fu0iFzOgn6um67aAVz87f/oYJrd7eVZnis3L6OrtMGoK90y0M1/ePAkw+nZkueBVZtUZp6amNHWWPoi18zoaa0vaWzE8aE01+5MUF8TX/OaIKvrzPkZBlbZ4VhJpZjpWnW7NYVt1RYRkSIF/VzX9Hi/9V+3q5WamHFsqHpDUkfSs2XZuZhPRwJdNJHJsqOljlisPEVuKQNSnXMcH5pcd2kRLs50RTEgtZDIiC8C3wWuNbNBM/vnhWy3Xmurdhl+BhGRy87Kfi7wls729iaqegdjOdLoV9KRQBelMvNliYsIlDIg9cy5WdKzC+vuXASvP62+JsaZc9Frpt9wedE5d+cGzzvgY2s89yBeUSYiIiW0sp8rcDDZxkMnRqqymT6Xc4xOlieNPp+ZcfM1XXzzBe9IoHLN8lSDVGa+LHERgZ5EPd85VZritpAmevD+9012NEYyIFWJ9CIiVWhlP1fgQLKNCzMLkVxa2cjEdJaFJVe2nYv5bt7bxbnpLM8OX9474Mt12HWgp7WhZKn0x896TfTX7ty4T6u/s4nBC9Gb6VLRJSJShVbXOIkbAAAgAElEQVT2cwUOJdsBeGaw+vq6LmZ0lb/oOnyFN0NY7blmW+GcYzwzX5a4iEAQG1GKrK7jQ2n29q7fRB/QTJeIiJTEav1cgb29CeriMY5VYV/XxTT68u8o7GtvpLE2zoujmbLfK6qm5hfJLubKEhcRuBiQurW+Luccx4bSGy4tBvo7mkjPLjA5t7Cl+5aaii4RkSqzVj8XQF1NjOt2VWcz/Yi/y63cPV0AsZhxTU8LL45Nlf1eUbWc0VWGw64DPa1BQOrWZroGz89yYWbjJvpAssOLjRiM2GyXii4RkSqzVj9X4ECyjeNDaXK5giIPI2M4PUdt3NjRXL4iIN9AT8tlPdM1Me2l0Zd192LCn+naYir9cX8ZuNCiq78ziI2IVl+Xii4RkSqzVj9X4GBfO1Pzi7wyMR3yyLZmJD1Hb2tDaLsJB3oTjEzOkZ6N1hJUWMqZRh8IUulHt9jTdWwoTU3M2FdAEz14y4tA5A6+VtElIlJF1uvnChxIerMB1dYk7iXEl39pMTDgF62nxi7P2a5UpvzLi2ZGd6Ke8S3OdB0bSjPQm6ChduMmevCKvea6uGa6RESkeOv1cwUGelpoqI1VXV/XSHqOnSEey7PXPyLmxdHLs69rPJPFDDqbyruc29Nav6WZLi+JPs2BvtaCv8fM6O9sitwORhVdIiJVZKN+LoCaeIw37m7jaBXFRjjnls9dDEuyo5GG2hgvXsYzXZ1NddTEy1sK9CYattTTNXRhlvMzCwXvXAwkOxo10yUiIsXbqJ8rcKCvjeNDkyxVSTP9hZkF5hdzoWR0BS7uYLxMi66p+bL2cwV6Wrd2/uLxIS/AttAm+kCyo4nB87N4B+dEg4ouEZEq4Zzj8Q36uQIHk23MLizx0nh1FBTDfjBqmDNdAAM9ict2eXFi2jvsutx6WxuYnFtkbqG4VPrjQ2niMeO6XYUvL4I305WZX+TCTHQ2SqjoEhGpEmfOzXJ2g36uwEG/mb5a+rpGJr3emzAyuvIN9LYwnJ5jKmIhmmFIZUKa6QpS6YtcYjw2lPb7FAtrog/0d/pZXRHawaiiS0SkShTSzxW4squF5ro4x6qkr+viTFd4jfTgzXQBl+USY3jLi14hXUwz/cUm+s0tLYI30wVwJkJ9XSq6RESqxGOnJwrq5wKIx4w39rVxtEpiI0bSc8RjXrxAmPb2+rERl1lI6mx2iensUlnjIgK9rcXPdA2n55iYzm66nwvyZ7pUdImIyCYUks+10qFkG8+enWRhKVfm0W3dcHqOnkQ98ZCCUQPJjibqa2K8cJn1dS1ndIWyvOjPdBXRTH9sk0n0+VobamlrrI1UbISKLhGRKrCZfq7AgWQ784u5qigohtOzofdzgTcjeDnuYBz3i67uEIqujqZaauNW1KHXx4fSxAz2b7KJPhC12AgVXSIiVWAz/VyBg/7swLEqaKYPO6Mrn3cGY/QL01IK4wiggJnRk2hgrMiZroGeBI11m2uiD/R3NEXqKCAVXSIiVWAz/VyBK3Y0kWioiXxfl3POS6NvDbeJPjDQm+DsZbaDcfmw6xAiI8DL6trsTFfQRF/M0mIgmOmKSlaXii4RkYgrpp8LvBmGg8m2yM90Tc4tMpNdquhMF1xeZzAGM12hFV2JzQekjk7Ok8pkN3X8z0r9nU3MLeRIZbJFv0YpqegSEYm4Yvq5Agf62nluZJL5xeKCKcMw4sdFVKKnC/LOYLyciq7MPK0NNdTXFLdst1m9rQ2bnukKmuiDA9yLEbXYCBVdIiIRV0w/V+BQso2FJcdzw9HtWRpOez03lZrp6u/0djBeTn1dqUyWrhDjOXoS9aRnFzaVSn9suYm++KIragGpKrpERCKumH6uQDBLEOW+rkrPdMVjxtXdl9cOxvGQ0ugDQUDq+CZmu44Ppbmmp6XoJnqAvnZ/puucZrpERGQDxfZzBfraG+lsrot0Mv1weg6zi3lOlTDQ28KLl1FAaiozH0pcRCA4CmgzfV3HhtJcv7v4WS6A5voadjTXaaZLREQ2tpV+LvCa6Q/0tUX6DMaR9BxdLfXU1VTun6S9vQmGLsySmV+s2BjCNJEJ57DrQK8/01VoX9fo5BzjU/Nb2rkYSHY2RSarS0WXiEiEbaWfK3Aw2caLYxlms9Fsph+erFxGV+Cay2gHY3YxR3p2IdTlxaDoKnSmK9hxu5Um+oAXG6GZLhER2cBW+rkCB/raWMo5nh2eLOHISmckPcvO1soWXcs7GC+DZvqJ6fCCUQNBKv1ogecvHhtKY1tIos/X39HE0PlZcrnKZ3Wp6BKRbc3MbjOz583slJnds8rzZmaf8Z8/amY3+I83mNn3zOwZMzthZr8e9ti32s8VOJhsB4hsX1cl0+gD/R2N1NXELotm+tSUl1nVFeLy4nIq/VRhM13Hh9Jc3d1Cc33Nlu+d7Ggku5Qr6hiiUlPRJSLblpnFgc8CtwP7gTvNbP+Ky24HBvyPu4B7/cfngXc65w4BbwJuM7ObQhm4b6v9XIGdbQ30JOoj2deVmV9kam6RnW2VSaMP1MRjXNXVfFnMdC0fdh1iZARAd6KesQJnuo6fTXOgBP1ccDE2IgpZXSq6RGQ7uxE45Zw77ZzLAl8C7lhxzR3AF5znMaDdzHb5XwfTHrX+R6jrE6Xo5wocTLZFMjYiiIuo9EwXeEuML1wGOxjDPOw6X29rfUEzXWNTc4xOlqaJHvICUiMQG6GiS0S2sz7gTN7Xg/5jBV1jZnEzexoYA/6nc+7xMo71EqXo5woc6GvnpfFM5HbnVTqjK99ATwtDF2aZjtifUakFM11h7l4ELxKkkJ6u40ESfYmKriCrKwrN9Cq6RGQ7W60RauVs1ZrXOOeWnHNvApLAjWZ2/ao3MbvLzI6Y2ZHx8fEtDXh5ACXq5wocTLbhHJyI2GxXpdPo8w34zfTbfQfjRCZLU12cprqt90ttRm9rYan0xwYnMYM37t56Ez1AQ22c3tZ6zXSJiJTZINCf93USOLvZa5xzF4BvAretdhPn3P3OucPOucPd3d1bHTNQun6uQLBUcyxiRVcw09Vb4d2L4AWkwvY/gzEVchp9IAi/3SiV/thQmqu6mkvSRB9IdjRppktEpMyeAAbM7EozqwPeDzyw4poHgA/5uxhvAtLOuWEz6zazdgAzawTeBTwX1sBL2c8FXhPz7raGyDXTD0/O0dlcR0NtOAcvr+eKzibq4tv/DEav6Ap3aRGgp9Ur9Dbq6zo+lC5ZP1egv6NRjfQiIuXknFsEPg58AzgJfNk5d8LM7jazu/3LHgROA6eAPwQ+6j++C/g7MzuKV7z9T+fcX4c19lL2cwUOJts5GrHYiJH0XMUzugI18RhXdTdv/5muqWxFZ7rW6+san5pnZHKuZP1cgWRHE8PpORaXciV93c0Kd0FXRCRkzrkH8Qqr/Mfuy/vcAR9b5fuOAm8u+wBXUep+rsCBZBsPnRghPbNAW1NtyV53K4bTc+yOQD9XYKA3wVOvna/0MMoqlZnnLXs6Qr9vbzDTtU4qfdBEX/KZrs5GlnKO4fTccoREJWimS0QkYkrdzxU46B+pcvxsdJYYR9Kzkdi5GBjoaWHw/Cwz2e25g3FxKce5mcrMdHU01VETM0bX6ekKiq5SNdEHkh1eoVXpvi4VXSIiEVPqfq5AsGQTlb6uuYUlzs8sRGLnYmCv30z/0th0hUdSHudnFnAu3DT6QCxm9GwQkBo00ScaSjsT298RjYBUFV0iIhFTjn4ugPamOt7Q2cSxoWj0dV3M6KpsGn2+a3q82IgXtmkz/XIafQVmugB6Wtc/CqgcTfQAu9obiBkMVjg2QkWXiEiElKufK3Ag2RaZma7hCKXRB/bsaKI2btu2mb7iRdc6M10TmXnOpkvfRA9QG4+xq61Ry4siInJRufq5AoeSbQyen2UiU/nDf0cmvX8Ao9TT5Z3B2LJtYyMuFl3hLy+Cl8c2usZM17EyNdEHkhGIjVDRJSISIeXq5woc6GsHohGSGsx0RSUyIjDQ27J9Z7qmskD4h10HehL1XJhZPZV+uYm+r7RN9IEoBKQWVHSZ2W1m9ryZnTKze1Z5vsPM/srMjprZ9/KPyjCz/8PMTpjZcTP7oplF6/9dIiIRUq5+rsD1/j9oxyKwxDiSnqO1oaakyeOlMNCT4Mz5GWaz6x9XU41SmXnqamIkKvRnHpw8sFoq/bGhNHt2NNFa4ib6QH9nIyOTc8wvVu5/1w2LLjOLA58Fbgf2A3ea2f4Vl/0K8LRz7iDwIeDT/vf2Af8SOOycux6I4yVCi4jICuXu5wJINNRyVXczRyMy07UrQk30gb29LTgHL41vv9mu8cw8Xc11Zfv7tZHudVLpjw9Nlm1pEbyZLudg+ML6ifjlVMhM143AKefcaedcFvgScMeKa/YDjwA4554D9phZr/9cDdBoZjVAE5eeeyYiIpS/nytwsK8tMjNdUernCgRnMG7HHYwTmWzFlhYBev1U+pXN9OemswxdmC1LE32gv8Mr8CvZ11VI0dUHnMn7etB/LN8zwE8CmNmNwBVA0jk3BPwO8BowjHem2d+sdhMzu8vMjpjZkfHx8c39FCIi20C5+7kCB5LtjEzOrZsMHgZvpit6RdcVO5q37Q7GSh12HQjOXxxd8Xcv6OcqZ9GV7Kx8QGohRddqc5Buxde/CXSY2dPAzwNPAYtm1oE3K3YlsBtoNrMPrHYT59z9zrnDzrnD3d3dBf8AIiLbRbn7uQJBMn0lm+mzizlSmflIznTVxmNc2dW8LXcwVuqw60Cnn0o/tqKn69hyE335iq6drQ3UxIwzFczqKqToGgT6875OsmKJ0Dk36Zz7Oefcm/B6urqBl4F3AS8758adcwvAXwJvK8nIRUS2kTD6uQJv3N1KzOCZCi4xBjMdUZzpAu8Mxu0205XLOW95sYIzXbGY0Z2ov+TQ6+NDaa7Y0URbY/nOBI3HjN3tjZyJ+EzXE8CAmV1pZnV4jfAP5F9gZu3+cwAfBh51zk3iLSveZGZN5r2L3AqcLN3wRUS2h7D6uQCa6moY6ElwbLByyfQjk9FLo8830NPCa+e21w7G9OwCizlX0aILVk+lP1amJPqV+jsbGYxyT5dzbhH4OPANvILpy865E2Z2t5nd7V92HXDCzJ7D2+X4Cf97Hwe+AnwfOObf7/6S/xQiIlUurH6uwIFkG8eG0ji3slskHFFMo8+3tzex7XYwLgejVrCRHi5NpT8/nWXwfHmb6AP9HU2cOVe5ma6Cgjqccw8CD6547L68z78LDKzxvZ8CPrWFMYqIbHth9XMFDibb+MqTgwyn59jdHv5s00g6emn0+Qb8/x1eHJsKZQYmDKmMH4zaXLmeLoDe1nqOvHJu+evjZ8vfRB9IdjSSyswzt7BEQ2287PdbSYn0IiIVFmY/VyD4B65S5zAOp+dorotXLKRzI3u6mqmJGS+Oaqar1HoTDZyfWVgOKV1uot9dniT6fP3LOxgrs8SooktEpMLC7OcKXLerlZqYcWyoMn1dQUZXpUI6NxLsYHxhOxZdFe/p8u4fpNIfH0rT39lIe1P5Z+CSy1ldlVliVNElIlJhYfdzATTUxrl2Z6KiM11RTKPPN9Dbwqmx8GMj/uqpQb72TOlzxFOZeeIxo72MOwQL0eMfBRTsYDw2lA5laRG8ni6AwQrFRqjoEhGpsLD7uQIHk20cHaxMM31U0+jzDfQkePXczKqHM5fL4lKOX//as/ziV57h7IXSzsakprLsaK4jFqvs7GJPIpjpmiM9s8CZc7Oh9c11tdRTVxOrWECqii4RkQpyzvH4y+dC7ecKHOhrJz27EPpursWlHGNT0UyjzzdQgTMYn3z1PBdmFphbyPHbDz1X0teudBp9oDdvpivMJnrwcsKSHY0VOwpIRZeISAUNnp9l6MJsqP1cgSCZ/mjIfV3jmXlyLro7FwN7exMAoTbTP/LcGLVx42fftof//vRZvv/a+ZK9diozz44KptEHglT60cm55Sb663eHt0M0WcHYCBVdIiIV9N0K9HMF9vYmqIvHQj/8OuoZXYE9O/wdjCH2dT18cpSbrtrBL/7YtfQk6vm3X3uWXK40y7+pTJbuCMx0Ban0Y1PzHBtKk+xopCPEGIv+jsoFpKroEhGpoEr1cwHU1cS4blf4zfQjftG1szXajfR1NTH2hLiD8fR4htPj09y6r4fm+hp+6bZ9PH3mAl99ZmjLr+2c85YXKxwXEehJ1DM6OcfxEJvoA/2dTZyfWSAzvxjqfUFFl4hIxTjnePx0Zfq5AgeT7RwfSpdsNqUQ1TLTBV5I6qmQzmB85OQYALde1wvAT765j4PJNn7r688zk91agZCZX2R+MVfRw67z9bQ28NJYhlcnZkIPnw1iIyox26WiS0SkQirZzxU4kGxjan6RlyemQ7vnSHqW+poY7U2VjS4oxEBvglcnpkPZwfjwyVH27UwsB3jGYsYnf3w/I5Nz3Pet01t67eU0+ggsL4I303XWL77DLrqC2IhK9HWp6BIRqZBK9nMFgmb6MPu6vIyu6Aaj5hvoaSHn4PR4eYvSCzNZjrx6nluv63nd44f3dPLeQ7v5g2+9xNAWIiSiEowaCHYwQng7FwOa6RIRuQxVsp8rcE13Cw21sVD7uqohoyuwvIOxzM3033x+nKWc413+0mK+e27fB7ClCImUn/4ehd2LcDGrq6+9kc6Qz4LsbK6jqS6umS4RkctFFPq5AGriMd64uy3U44CqIY0+sKeriXgIZzA+fHKUrpZ6DiXbL3mur72Rj9xyFV99+ixPvlpchERq2ltejMLuRbg403V9X/nPW1zJzMvq0kyXiMhlIgr9XIEDfW0cH5pkKYRm+lzOMTpZPTNd9TVx9uxoKutMV3Yxx7deGOed+7rXTIv/yA9dTW9rPf/2r4uLkEhNzWNG6LNKawnOXwx7aTHQ39FUkfMXVXSJiFTAqbEM9TWxivZzBQ4m25hdWAoleT01Pc9izlXFzsXAQE+irDNdT7xyjqm5xeVdi6tprq/hl35sH8+cucB/f3rzERKpzDwdTXXUxKPxz/5AT4KfekuS9x3qq8j9kx2NDJ6bCf0IrGj86YuIXGbesa+Ho7/2oxXt5woc9Je0njlT/iXGixld1VN07e1t4ZWJaeYXy7OD8eGTo9TVxLh5oGvd6/7hm/s4lGzjtx56btMREt4RQNGY5QIvA+0//tQh3rCjqSL37+9sYmp+kcnZcLO6VHSJiFRIfU08Ejv4rupqprkuvnwkSzldzOiqjp4ugGt6E2Xbweic4+GTo7z96h001dWse20sZnzyvfsZnZznvm++tKn7pDLZyOxcjIJkEBsRcl+Xii4RkctcLGZc39cWyg7G5ZmuKlpe3NvrzUa+WIaQ1BfHMpw5N7vu0mK+t1zRyfsO7eYPHj29qQiJqBx2HRWVio1Q0SUi25qZ3WZmz5vZKTO7Z5Xnzcw+4z9/1Mxu8B/vN7O/M7OTZnbCzD4R/ujDczDZxrPDkyws5cp6n+H0HLVxY0dEGroLcWVXs7+DsfTN9A+fHAW4JJ9rPb98+z7M4De/XniERGoqGoddR0UQQBt2bISKLhHZtswsDnwWuB3YD9xpZvtXXHY7MOB/3AXc6z++CPyCc+464CbgY6t877ZxINlOdjHHC2UoLPKNpGfpbW1Yc5deFNXXxLliR1NZmukfOTnG9X2tm1pu7Wtv5K5bruZrz5zlyVfPbXj9bHaJ6eySZrrytDXWkmio0UyXiEgJ3Qiccs6dds5lgS8Bd6y45g7gC87zGNBuZrucc8POue8DOOemgJNAZbZaheBgXzjJ9EEafbUZ6GnhhRLHRkxk5vn+a+e5dV9hS4v57v6hq9jZ2sCvf23jCIkgjT4qGV1RUYnYCBVdIrKd9QFn8r4e5NLCacNrzGwP8Gbg8ZKPMCKu2NFEa0MNz5S56BqZnGNnFTXRB/b2Jnh1YqakOxj/9rkxnGPVFPqNNNXV8Mu3X8vRwTR/9dT6ERLLRwAltLyYrxIBqSq6RGQ7W20Na+W0wLrXmFkL8BfAv3LOTa56E7O7zOyImR0ZHx8verCVZGYcTLaXNZneOVe1M13X9LSwlHO8nCrdDsZHTo7R21pfdCr7HYf6ONTfzm899BzT82tHH0TtsOuo6O9s4sy52VCzulR0ich2Ngj0532dBM4Weo2Z1eIVXH/mnPvLtW7inLvfOXfYOXe4u7u7JAOvhAPJNp4fmWJuoTx5VOdnFsgu5qoqoyuwfAZjifq65haWePTFcW69rrfo2JBYzPjkj+9nbGqe+761doRE1A67jor+jkZmF5aY8I9ICoOKLhHZzp4ABszsSjOrA94PPLDimgeAD/m7GG8C0s65YfP+Jfwj4KRz7vfCHXZlHOxrY2HJ8fxIeZrph9Ne/0w1znRd2dVMzCjZDsbHTk8wk13iXZvYtbiat1zRwR1v2s39j55ec6ksOOw6KkcARUWQ1TUYYl+Xii4R2bacc4vAx4Fv4DXCf9k5d8LM7jazu/3LHgROA6eAPwQ+6j/+duCDwDvN7Gn/493h/gThOpD0mumPlikktRozugINtXH27GguWVbXIyfHaKyN87ar10+hL8Qv37Z+hMTEdJZEQw0NtfEt32s7uRgbEV5f1/rxtyIiVc459yBeYZX/2H15nzvgY6t833dYvd9r2+prb6SzuY5jgxeAK0r++tWYRp/vmp6WkkRqOOd45OQoPzjQVZJCaHd7Ix+55Wo+/ciL/OzbznF4z+sPUR/PzGvn4iouBqRqpktERELmNdOXL5l+JD1HPGZ0J6qzABjobeGViRmyi1sLkD05PMXZ9NyWlxbzfWSdCInUlNLoV9NcX0Nnc12oRwGp6BIRkWUH+9p4YXSK2Wzpm+mH03P0JOqJV1Ewar69vYmS7GB8+OQoZvDOIvK51tJUV8M9t+/j2FCav1wRIZHKzCsuYg1ebIRmukREpAIOJNvJOXh2uPSzXSOTs1XZRB+4pic4g3FrS4yPnBzlULK95DN+7zu0mzf1t/PbKyIkdNj12vo7mhgMsadLRZeIiCw7GDTTl2GJ0cvoqs5+LoCru1uIGbywhdiIsck5nhlMl3RpMRCLGZ98rxchce83vQiJ7GKO9OwCO5pVdK0m2dHI4IXZDVP9S0VFl4iILOttbaC3tZ4Hjw2zVMJ/iJxzjKTnqnLnYqChNs4bOps4tYWZrkeeGwPg1iJS6Atxwxs6+Ik37eb+b5/mzLkZJqaVRr+eZGcT2cUc436WWbmp6BIRkdf5hR+5lideOc/v/M3zJXvNyblFZrJLVb28CDDQm9jSTNcjJ0fpa29k385ECUf1er902z5iBr/50HNMKI1+Xf3+DsawYiNUdImIyOv8kx/o584b38C933yJh46PlOQ1qzmjK99ATwuvpKaL2sE4m13iO6dSvOu6nqJT6Auxu72Ru3/oav7H0WG+fnwYUNG1lrADUlV0iYjIJX7tffs51N/O//Xnz3CqBIGg1ZxGn29vb4LFnOOVic3vYPz7UynmFnJlW1rM95FbrmZXWwP3fes0gHK61pDUTJeIiFRafU2ce3/6BuprYnzkT46QWedA5UJcnOmq3kZ6yNvBWMQS4yPPjdJSX8Nbr+rc+OItaqyLc8/t+5b78tTTtbqG2jjdiXrNdImISGXtbm/kP9/5Zl5OTfOLf/4MXnh/cYbTc5hBT5UGowau6WnBjE0n0+dyjkdOjnHL3i7qa8I5jud9h3bz5je0k6ivoalOB9Cspb+jMbSAVBVdIiKyprdd08U9t+/j68dHuP/R00W/zkh6ju6Wemrj1f3PzsUdjJub6Tp+Ns3Y1Dy3ljAQdSNmxn0feAuf+5nDod2zGiU7mjTTJSIi0fC/33wV7zmwi9966Dn+16lUUa8xPDlX9f1cgYGexKZnuh5+dpSYwTv2lT6faz29rQ289aodod6z2vR3NnL2wmxJI1LWoqJLRETWZWb81j8+yFXdLXz8i09x9sLmZwVG0rNVv3MxMNDbwsupaRaWCt/B+PDJMd5yRQedzeqtippkRxOLOcfI5FzZ71VQ0WVmt5nZ82Z2yszuWeX5DjP7KzM7ambfM7Pr855rN7OvmNlzZnbSzP5BKX8AEREpv5b6Gv7gg28hu5jjX/zpk8wtbO5sxmpPo8+3t7eFxZzj1QJ3MJ69MMuzw5Oh7FqUzev3YyPC2MG4YdFlZnHgs8DtwH7gTjPbv+KyXwGeds4dBD4EfDrvuU8DDznn9gGHgJOlGLiIiITr6u4WfuenDvHMYJpf/9qJgr8vM7/I1Nzi9pnp6vGCTQsNSX3k5ChAWY7+ka3r7/R+GQijr6uQma4bgVPOudPOuSzwJeCOFdfsBx4BcM49B+wxs14zawVuAf7Ify7rnLtQstGLiEiobrt+Jx/94av54vfO8N+eeK2g7wniIrZLT9fV3d4OxkJjIx4+OcaeHU1c3d1S5pFJMXa1NWIWkZkuoA84k/f1oP9YvmeAnwQwsxuBK4AkcBUwDvwXM3vKzD5nZs1bHrWIiFTML/zotdw80MW/+eoJjg5u/Hv0ckZX6/Youhrr4vR3NPFCAWcwTs8v8t2XJrj1ut6yptBL8epqYuxqbQglNqKQomu1vyUrW/x/E+gws6eBnweeAhaBGuAG4F7n3JuBaeCSnjAAM7vLzI6Y2ZHx8fFCxy8iIiGLx4xPv//NdLfUc/efPMnEBocFX0yj3x49XeD1dZ0qYKbr2y+myC7luFVLi5EWVmxEIUXXINCf93USOJt/gXNu0jn3c865N+H1dHUDL/vfO+ice9y/9Ct4RdglnHP3O+cOO+cOd3d3b/LHEBGRMHU213HfB95CajrLv/zSUyyus5MvmOnqaa3uYNR81/QkOJ3KbLiD8eGToyQaaviBPeVPoZfiJTsbGYzI8uITwICZXWlmdcD7gQfyL/B3KAb7YD8MPOoXYiPAGTO71n/uVuDZEo1dREQq6Ga0OAUAAAqpSURBVECyjX//E9fz96cm+J2/eWHN64Yn59jRXEdDbThJ7GHY29vCwpLj1Ym1/6Feyjn+7rkx3nFtT9WHwm53yY4mRibnijrIfDM2/FvgnFsEPg58A2/n4ZedcyfM7G4zu9u/7DrghJk9h7fL8RN5L/HzwJ+Z2VHgTcBvlPIHEBGRyvknh/v5Z299A/d96yUeOj686jUj6blts3MxEOxgfHGdkNSnz1xgYjqrpcUq0N/RSM5dXAovl4IOY3LOPQg8uOKx+/I+/y4wsMb3Pg3oDAIRkW3qU+/dz7NnJ/mFLz/DNT2J5UOhA8PpOfrat1fRFZzB+OJYhtvXuObhk6PEY8YP71XRFXVJP6tr8PwsV+wo334/zXeKiMiW1NfEufcDN9BQG+cjf3KEzPzi657fTmn0gca6OMmOxnWPA3rk5Cg37umkrak2xJFJMYKsrnLHRqjoEhGRLdvV1sh//mdv5pWJGX7xz5/BOW+T+9zCEudnFrbVzsXAQE9izYOvz5yb4YXRjJYWq8TO1gZqYlb2HYwqukREpCTednUX99y2j68fH+EPHj0NbL+MrnwDvS2cHp9edefmw8sp9Dr6pxrUxGPsai9/VldBPV0iIiKF+PDNV/L04AV++6HnONDXRswPBN0uafT5BnoSZJdyvHpu5pK0+YdPjnJ1dzN7upQHXi36O5q0vCgiItXDzPjtf3SQq7tb+PkvPsX3XzsPsO16usCLjYBLdzBOzi3w+OlzvGu/ZrmqSbKjUcuLIiJSXZrra7jvg28hu5jjd//meWB7Fl3B7NbKMxgffWGcxZzT0mKV6e9oYmxqnrmFpbLdQ0WXiIiU3NXdLfzuPzlEzkFbYy1Ndduvm6W5vsbbwbiimf7hZ0fpaKrlhjd0VGhkUoykv4Nx6EL5Zru23/8LREQkEn7sjTv51fdcx9kLc5UeStkM9LS8bnlxcSnH3z0/zq3X9RCP6YDratLvZ3WdWaVHr1RUdImISNl8+OarKj2Estrbm+DvT02wuJSjJh7jyVfPk55d0NJiFervvBiQWi5aXhQRESnSNT0tZJdyvObvenv45Ci1cePmga4Kj0w2q7ulnrqaWFljI1R0iYiIFGlvr3cG4wt+M/0jJ8e46aodJBqUQl9tYjEj2V7eHYwqukRkWzOz28zseTM7ZWb3rPK8mdln/OePmtkNec993szGzOx4uKOWahGcM3lqbIrT4xlOp6a1tFjF+joaGSxjVpeKLhHZtswsDnwWuB3YD9xpZvtXXHY7MOB/3AXcm/fcHwO3lX+kUq2a62voa2/khdEMj5wcA9DRP1Wsv7OJM5rpEhEpyo3AKefcaedcFvgScMeKa+4AvuA8jwHtZrYLwDn3KHAu1BFL1RnobeHFsQz/8+Qo+3YmSPq74KT6JDsaOTedZXrFoe2loqJLRLazPuBM3teD/mObvUZkTXt7E7w0luHJV89rabHKBbER5errUtElItvZakFJrohr1r+J2V1mdsTMjoyPj2/mW2UbCHYwLuWclharXLLDC0gdLNMORhVdIrKdDQL9eV8ngbNFXLMu59z9zrnDzrnD3d3dRQ1Uqlewg7GrpZ5DyfYKj0a2IsjqKtfB1yq6RGQ7ewIYMLMrzawOeD/wwIprHgA+5O9ivAlIO+eGwx6oVK9relowg3fu6yamFPqqtqO5jsbaeNmWF5VILyLblnNu0cw+DnwDiAOfd86dMLO7/efvAx4E3g2cAmaAnwu+38y+CPww0GVmg8CnnHN/FO5PIVHXUl/DH37wMAeSbZUeimyRmZHsaCxbQKqKLhHZ1pxzD+IVVvmP3Zf3uQM+tsb33lne0cl28a79aqDfLvo7mzTTJSIiIlJuv/Lu66iLl6f7SkWXiIiIiC84ZaAc1EgvIiIiEgIVXSIiIiIhUNElIiIiEgIVXSIiIiIhUNElIiIiEgIVXSIiIiIhUNElIiIiEgIVXSIiIiIhUNElIiIiEgIVXSIiIiIhMO+s12gxs3Hg1QIv7wJSZRzOVkR1bBrX5kV1bFEdF2xubFc457rLOZiw6P2r7KI6Loju2KI6Loju2DY7roLewyJZdG2GmR1xzh2u9DhWE9WxaVybF9WxRXVcEO2xRUWU/4yiOraojguiO7aojguiO7ZyjUvLiyIiIiIhUNElIiIiEoLtUHTdX+kBrOP/b+f+QrOq4ziOvz9sRWmFdVHUJmgglkhlRFhBF5mwSlyXRYVQl/2xCErpPoIiCoq6sJrQMGIZSVA5LOimIrIwbZVSoavVhOgPdWHSt4tz9vAwh7C1nd/3yOcF4znnXH04Z89n3/NnJ2s255q9rNmy5oLc2bLIvI+yZsuaC/Jmy5oL8mZbkFytf6bLzMzMrA1OhStdZmZmZum1euiSNCDpG0mHJG0pnQdA0lJJH0gak3RA0ubSmbpJ6pH0uaS3S2fpJmmJpBFJX9f77prSmQAkPVQfx/2Sdkg6o2CWlyVNStrfte08SaOSDtaf5ybJ9WR9LPdJelPSkqZzZef+mpuMHZa1vyBPh2Xtr5NkW5AOa+3QJakHeB64CVgF3C5pVdlUABwHHo6IS4G1wL1Jck3ZDIyVDjGDZ4F3I+IS4HISZJTUBzwAXBURq4Ee4LaCkYaAgWnbtgB7ImIFsKdeb9oQJ+YaBVZHxGXAt8DWpkNl5v76XzJ2WLr+gnQdNkTO/oIGO6y1QxdwNXAoIr6LiGPAa8Bg4UxExERE7K2X/6T68vWVTVWR1A/cAmwrnaWbpHOA64GXACLiWET8VjZVRy9wpqReYBHwU6kgEfEh8Ou0zYPA9np5O3Bro6GYOVdE7I6I4/Xqx0B/07mSc3/NQcYOS95fkKTDsvYXNNthbR66+oAjXevjJCoHAEnLgDXAJ2WTdDwDPAL8WzrINBcDR4FX6tsG2yQtLh0qIn4EngIOAxPA7xGxu2yqE1wQERNQ/cEEzi+cZyZ3A++UDpGM+2tuMnZYyv6CVnRYG/oL5rHD2jx0aYZtaf4VU9JZwBvAgxHxR4I8G4DJiPisdJYZ9AJXAi9ExBrgL8pdZu6ony8YBJYDFwGLJd1ZNlW7SHqM6pbVcOksybi/Zilxh6XsL3CHzYf57rA2D13jwNKu9X4K3vrpJuk0qsIajoidpfPUrgM2SvqB6lbGDZJeLRupYxwYj4ipM+oRqhIr7Ubg+4g4GhH/ADuBawtnmu4XSRcC1J+ThfN0SNoEbADuCL+bZjr31+xl7bCs/QX5Oyxtf8HCdFibh65PgRWSlks6nerhwF2FMyFJVPf2xyLi6dJ5pkTE1ojoj4hlVPvq/YhIccYTET8DRyStrDetA74qGGnKYWCtpEX1cV1Hkgdku+wCNtXLm4C3CmbpkDQAPApsjIi/S+dJyP01S1k7LHF/Qf4OS9lfsHAd1tqhq37A7T7gPapfotcj4kDZVEB1NnYX1VnYF/XPzaVDtcD9wLCkfcAVwOOF81CfuY4Ae4Evqb4vxd6eLGkH8BGwUtK4pHuAJ4D1kg4C6+v1DLmeA84GRuvvwItN58rM/XXKSddfkKvDsvbXSbItSIf5jfRmZmZmDWjtlS4zMzOzNvHQZWZmZtYAD11mZmZmDfDQZWZmZtYAD11mZmZmDfDQZWZmZtYAD11mZmZmDfDQZWZmZtaA/wBhe0o0pIS2JQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "# import prep_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot Accuracy & Loss\n",
    "def plot_acc_loss(train_test, accuracy, loss_):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(accuracy)\n",
    "    plt.title (f'{train_test} Accuracy')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(loss_)\n",
    "    plt.title (f'{train_test} Loss')\n",
    "    plt.show()\n",
    "\n",
    "# Function to train model\n",
    "def train_model(model, num_epochs, dataloader, device, criterion, optimizer):\n",
    "    n_correct = 0\n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    total_samples = 0\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for i, (X_train, y_train) in enumerate(dataloader):\n",
    "            X_train = X_train.to(device)\n",
    "            y_train = y_train.to(device)\n",
    "            # Forward pass\n",
    "            yhat_train = model(X_train)\n",
    "            loss = criterion(yhat_train, y_train)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(yhat_train.data, 1)\n",
    "            n_correct += (predicted == y_train).sum().item()\n",
    "            total_samples+=len(y_train)\n",
    "        \n",
    "        # Loss & accuracy per epoch\n",
    "        train_loss.append(loss.item())\n",
    "        train_accuracy.append(n_correct/total_samples)        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs} => Training Loss: {loss.item():.4f}')\n",
    "    \n",
    "    plot_acc_loss(train_test='Train', accuracy=train_accuracy, loss_=train_loss)\n",
    "\n",
    "    return (model)\n",
    "\n",
    "# Function to test model\n",
    "def test_model(model, dataloader, device, criterion):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        test_accuracy = []\n",
    "        test_loss = []\n",
    "        total_samples = 0\n",
    "        for i, (X_test, y_test) in enumerate(dataloader):\n",
    "            X_test = X_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            yhat_test = model(X_test)\n",
    "            loss = criterion(yhat_test, y_test)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(yhat_test.data, 1)\n",
    "            n_correct += (predicted == y_test).sum().item()\n",
    "            total_samples+=len(y_test)\n",
    "            \n",
    "            # Append loss & accuracy\n",
    "            test_loss.append(loss.item())\n",
    "            test_accuracy.append(n_correct / total_samples)\n",
    "            \n",
    "        # Print Test Accuracy & Loss\n",
    "        print (f'Test Accuracy: {test_accuracy[-1]:.4f}')\n",
    "        print (f'Test Loss: {test_loss[-1]:.4f}')\n",
    "\n",
    "    plot_acc_loss(train_test='Test', accuracy=test_accuracy, loss_=test_loss)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def choose_model(option):\n",
    "    if (option == 'resnet'):\n",
    "        # Load pre-trained model\n",
    "        model = torchvision.models.resnet18(pretrained=True)\n",
    "        print ('ConvNet as fixed feature extractor')\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Parameters of newly constructed modules have requires_grad=True by default\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 5)\n",
    "    elif (option == 'vgg16'):\n",
    "        model = torchvision.models.vgg16(pretrained=True)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_features = model.classifier[6].in_features\n",
    "        features = list(model.classifier.children())[:-1] # Remove last layer\n",
    "        features.extend([nn.Linear(num_features, 5)]) # Add our layer with 5 outputs\n",
    "        model.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "    return (model)\n",
    "\n",
    "# Choose model\n",
    "# Add final fully connected layer or\n",
    "# FFE (Fixed Feature Extractor, freeze all but final layer)\n",
    "# model = choose_model('')\n",
    "# model = choose_model('resnet')\n",
    "model = choose_model('vgg16')\n",
    "model = model.to(device)\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 5\n",
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Define Loss & Optimzier\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Train model        \n",
    "model = train_model(model, num_epochs, dataloader_train, device, criterion, optimizer)\n",
    "# Test model\n",
    "test_model(model, dataloader_test, device, criterion)\n",
    "\n",
    "MODELPATH = './data/models/cnn_tl2.pt'\n",
    "torch.save(model, MODELPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torchvision.models.vgg16(pretrained=True)\n",
    "model\n",
    "list(model.classifier.children())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "mama\n"
     ]
    }
   ],
   "source": [
    "classes = traintest.classes\n",
    "model.eval()\n",
    "\n",
    "for im, la in dataloader_test:\n",
    "    img = im[0].view(1, 3, 128, 128).to(device)\n",
    "    yhat = model(img)\n",
    "    label = torch.max(yhat.data, 1)[1]\n",
    "    print (label.item())\n",
    "    print (classes[label.item()])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct =  75\n",
      "wrong =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import prep_data\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load model\n",
    "MODELPATH = './data/models/cnn_tl2.pt'\n",
    "model = torch.load(MODELPATH)\n",
    "model.eval()\n",
    "\n",
    "def predict_face(path, c):\n",
    "    im = Image.open(path)\n",
    "    im = img_transform(im)\n",
    "    im = im.view(1, 3, 128, 128).to(device)\n",
    "    yhat = model(im)\n",
    "    # print (yhat)\n",
    "    label = torch.max(yhat.data, 1)[1].item()\n",
    "#     print (label)\n",
    "    return (classes[label])\n",
    "\n",
    "idxs = np.random.randint(1,100, size=15)\n",
    "classes = traintest.classes\n",
    "correct = 0\n",
    "wrong = 0\n",
    "\n",
    "for c in tqdm(classes):\n",
    "    for idx in idxs:\n",
    "        pred = predict_face(f'./data/images/{c}/{c}_{idx}.jpg', c)\n",
    "#         print('pred=', pred, '\\t', 'actual=', c)\n",
    "        if (pred == c):\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "\n",
    "print ('correct = ', correct)\n",
    "print ('wrong = ', wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baba', 'dylan', 'mama', 'naomi', 'tyler']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_face(path, c):\n",
    "    im = Image.open(path)\n",
    "    im = prep_data.img_transform(im)\n",
    "    im = im.view(1, 3, 128, 128).to(device)\n",
    "    yhat = model(im)\n",
    "    # print (yhat)\n",
    "    label = torch.max(yhat.data, 1)[1].item()\n",
    "    return (classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(2.0)\n",
    "print ('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle - House Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/houseprice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice      0\n",
       "MSSubClass     0\n",
       "MSZoning       0\n",
       "LotFrontage    0\n",
       "LotArea        0\n",
       "Street         0\n",
       "YearBuilt      0\n",
       "LotShape       0\n",
       "1stFlrSF       0\n",
       "2ndFlrSF       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\n",
    "                                         \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"]\n",
    "\n",
    "\n",
    "df[cols].dropna().isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fghij'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "string.ascii_lowercase[:5]\n",
    "string.ascii_lowercase[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
